{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_handler_cross_NER\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_relying_on = 'deepset/roberta-base-squad2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_relying_on)\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: deepset/roberta-base-squad2 has context window size of 512\n"
     ]
    }
   ],
   "source": [
    "MODEL_CONTEXT_WINDOW = tokenizer.model_max_length\n",
    "print(\"Model: {} has context window size of {}\".format(pretrained_model_relying_on, MODEL_CONTEXT_WINDOW))\n",
    "MAX_SEQ_LENGTH = 384  # question + context + special 64\n",
    "assert MAX_SEQ_LENGTH <= MODEL_CONTEXT_WINDOW, (\"MAX SEQ LENGTH must be smallerEqual than model context window\")\n",
    "DOC_STRIDE = 128  # overlap between 2 consecutive passages from same document, 16\n",
    "MAX_QUERY_LENGTH = 32\n",
    "assert DOC_STRIDE < (MAX_SEQ_LENGTH - MAX_QUERY_LENGTH), (\"DOC_STRIDE must be smaller than MAX_SEQ_LENGTH - MAX_QUERY_LENGTH, otherwise parts of the doc will be skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_cross_NER_datasets = \"../../datasets/CrossNER/ner_data\"\n",
    "dataset_name = \"music\"\n",
    "path_to_questions = f\"./cross_ner_questions/{dataset_name}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album': 'A music album is a collection of audio recordings, typically songs, that are released together as a single package. Which are albums in the document ?', 'award': 'A music award is like a prize given to musicians or groups to acknowledge their achievements in areas like singing, writing music, and producing. Which are awards in the document ?', 'band': 'A music band is a group of musicians who play instruments and/or sing together. Which are bands in the document ?', 'country': 'A country is a distinct geographical area with its own government, borders, and population. Which are countries in the document ?', 'event': 'An event is a planned and organized occasion or happening, often with a specific purpose or goal, where people gather to participate or observe. Which are events in the document ?', 'location': 'A location is a specific place or position, usually defined by its geographical coordinates, where something exists or events occur. Which are locations in the document ?', 'misc': 'Apart from albums, awards, bands, countries, events, locations, musical artists, musical instruments, music genres, organisations, people and songs, which are other relevant information in the document ?', 'musicalartist': 'A musical artist is an individual involved in creating, performing, and often composing music. Which are musical artists in the document ?', 'musicalinstrument': 'A musical instrument is a tool or device to make music. Which are musical instruments in the document ?', 'musicgenre': 'A music genre is a category that classifies music based on shared characteristics, such as musical style, cultural influences, and thematic elements. Which are genres in the document ?', 'organisation': 'An organization is a structured group of people with a common goal, purpose, or function, often working together to achieve specific objectives. Which are organisations in the document ?', 'person': 'A person is an individual human being. Which are person but not musical artists in the document ?', 'song': 'A song is a musical composition typically consisting of lyrics and melody, often intended for singing or performance. Which are songs in the document ?'}\n"
     ]
    }
   ],
   "source": [
    "questions = data_handler_cross_NER.load_questions_from_txt(path_to_questions)\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "album\n",
      "30\n",
      "award\n",
      "35\n",
      "band\n",
      "25\n",
      "country\n",
      "25\n",
      "event\n",
      "35\n",
      "location\n",
      "31\n",
      "misc\n",
      "39\n",
      "musicalartist\n",
      "26\n",
      "musicalinstrument\n",
      "21\n",
      "musicgenre\n",
      "36\n",
      "organisation\n",
      "34\n",
      "person\n",
      "20\n",
      "song\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "for neTag, question in questions.items():\n",
    "    tokenized_examples = tokenizer(\n",
    "        question,\n",
    "        truncation=\"only_second\",\n",
    "        max_length=MAX_SEQ_LENGTH,\n",
    "        stride=DOC_STRIDE,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    print(neTag)\n",
    "    input_ids = tokenized_examples['input_ids']\n",
    "    input_ids = np.where(np.array(input_ids) > 1, input_ids, 0)\n",
    "    print(np.count_nonzero(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = data_handler_cross_NER.build_dataset_from_txt(os.path.join(path_to_cross_NER_datasets, dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', '2003', ',', 'the', 'Stade', 'de', 'France', 'was', 'the', 'primary', 'site', 'of', 'the', '2003', 'World', 'Championships', 'in', 'Athletics', '.']\n",
      "44\n",
      "['In', 'addition', 'to', 'relentless', 'touring', 'in', 'the', 'U.S.', 'and', 'Canada', ',', 'PUSA', 'made', 'multiple', 'tours', 'of', 'Europe', ',', 'Australia', ',', 'New', 'Zealand', 'and', 'Japan', '.']\n",
      "61\n",
      "['Barney', 'Bubbles', 'directed', 'several', 'videos', ',', 'including', 'the', 'Specials', \"'\", 'Ghost', 'Town', ',', 'Squeeze', \"'\", 's', 'Is', 'That', 'Love', 'and', 'Tempted', ',', 'Elvis', 'Costello', \"'\", 's', 'Clubland', 'and', 'New', 'Lace', 'Sleeves', ',', 'and', 'Fun', 'Boy', 'Three', \"'\", 's', 'The', 'Lunatics', '(', 'Have', 'Taken', 'Over', 'the', 'Asylum', ')', '.']\n",
      "115\n",
      "['Since', 'then', 'there', 'has', 'been', 'a', 'renaissance', 'in', 'Sacred', 'Harp', 'singing', ',', 'with', 'annual', 'conventions', 'popping', 'up', 'in', 'United', 'States', 'and', 'in', 'a', 'number', 'of', 'European', 'countries', 'recently', ',', 'including', 'the', 'United', 'Kingdom', ',', 'Germany', ',', 'Ireland', 'and', 'Poland', ',', 'as', 'well', 'as', 'in', 'Australia', '.']\n",
      "104\n",
      "['Three', 'of', 'the', 'labels', 'rejected', 'her', ',', 'saying', 'that', 'audiences', 'wanted', 'pop', 'bands', 'such', 'as', 'the', 'Backstreet', 'Boys', 'and', 'the', 'Spice', 'Girls', ',', 'and', 'there', 'wasn', \"'t\", 'going', 'to', 'be', 'another', 'Madonna', ',', 'another', 'Debbie', 'Gibson', ',', 'or', 'another', 'Tiffany', '.']\n",
      "97\n",
      "['Notable', 'Sun', 'Ra', 'albums', 'from', 'the', '1950s', 'include', 'Sun', 'Ra', 'Visits', 'Planet', 'Earth', ',', 'Interstellar', 'Low', 'Ways', ',', 'Super-Sonic', 'Jazz', ',', 'We', 'Travel', 'the', 'Space', 'Ways', ',', 'The', 'Nubians', 'of', 'Plutonia', 'and', 'Jazz', 'In', 'Silhouette', '.']\n",
      "89\n",
      "['Stevens', \"'\", 'albums', 'Tea', 'for', 'the', 'Tillerman', '(', '1970', ')', 'and', 'Teaser', 'and', 'the', 'Firecat', '(', '1971', ')', 'were', 'certified', 'triple', 'platinum', 'in', 'the', 'US', 'by', 'the', 'Recording', 'Industry', 'Association', 'of', 'America', '..', 'BBC', 'News', '.']\n",
      "84\n",
      "['He', 'has', 'won', 'Top', 'New', 'Male', 'Vocalist', 'from', 'Billboard', 'in', '1992', 'and', 'from', 'Academy', 'of', 'Country', 'Music', 'in', '1993', ',', 'and', 'Vocal', 'Event', 'of', 'the', 'Year', 'from', 'the', 'Country', 'Music', 'Association', 'in', '2007', '.']\n",
      "75\n",
      "['In', '1983', ',', 'the', 'lineup', 'of', 'Verni', ',', 'Skates', ',', 'Ellsworth', ',', 'and', 'Gustafson', 'released', 'the', 'Power', 'in', 'Black', 'demo', ',', 'a', 'recording', 'that', 'made', 'as', 'much', 'impact', 'in', 'the', 'underground', 'tape', 'trading', 'circuit', 'as', 'demos', 'by', 'up-and-coming', 'Bay', 'Area', 'thrash', 'metal', 'bands', 'such', 'as', 'Exodus', 'and', 'Testament', '.']\n",
      "121\n",
      "['Their', 'style', 'has', 'been', 'described', 'as', 'Rock', 'and', 'roll', 'with', 'a', 'renegade', 'stance', ',', 'what', 'in', 'later', 'years', 'would', 'be', 'dubbed', \"'\", 'Punk', 'rock', \"'\", '.']\n",
      "58\n",
      "['He', 'also', 'appeared', 'with', 'RBX', ',', 'Nas', 'and', 'KRS-One', 'on', 'East', 'Coast', 'Killer', ',', 'West', 'Coast', 'Killer', 'from', 'Dr.', 'Dre', \"'s\", 'Dr.', 'Dre', 'Presents', 'the', 'Aftermath', 'album', ',', 'and', 'contributed', 'to', 'an', 'album', 'entitled', 'The', 'Psycho', 'Realm', 'with', 'Psycho', 'Realm', '.']\n",
      "104\n",
      "['On', '9', 'June', '1892', 'the', 'Paris', 'Opéra-Comique', 'staged', 'Les', 'Troyens', 'à', 'Carthage', '(', 'in', 'the', 'Théâtre', 'de', 'la', 'Ville', 'as', 'its', 'premiere', ')', 'and', 'witnessed', 'a', 'triumphant', 'debut', 'for', 'the', '17-year-old', 'Marie', 'Delna', 'as', 'Didon', ',', 'with', 'Stéphane', 'Lafarge', 'as', 'Énée', ',', 'conducted', 'by', 'Jules', 'Danbé', ';', 'these', 'staged', 'performances', 'of', 'Part', '2', 'continued', 'into', 'the', 'next', 'year', '.']\n",
      "160\n",
      "['As', 'a', 'group', ',', 'the', 'Spice', 'Girls', 'have', 'received', 'a', 'number', 'of', 'notable', 'awards', 'including', 'five', 'Brit', 'Awards', ',', 'three', 'American', 'Music', 'Awards', ',', 'three', 'MTV', 'Europe', 'Music', 'Awards', ',', 'one', 'MTV', 'Video', 'Music', 'Award', 'and', 'three', 'World', 'Music', 'Awards', '.']\n",
      "92\n",
      "['The', 'album', 'experimented', 'with', 'a', 'diverse', 'number', 'of', 'genres', ',', 'including', 'contemporary', 'R', '&', 'B', ',', 'deep', 'house', ',', 'Swing', 'music', ',', 'Hip', 'hop', 'music', ',', 'Rock', 'music', ',', 'and', 'Pop', 'music', ',', 'with', 'Billboard', 'describing', 'each', 'as', 'being', 'delivered', 'with', 'consummate', 'skill', 'and', 'passion', '.']\n",
      "105\n",
      "['Chuck', 'Burgi', '(', '1991-1992', ',', '1992-1995', ',', '1996-1997', ')', ',', 'John', 'Miceli', '(', '1992', ',', '1995', ')', ',', 'John', 'O', \"'Reilly\", '(', '1995-1996', ')', 'and', 'Bobby', 'Rondinelli', '(', '1997-2004', ')', '.']\n",
      "79\n",
      "['In', 'addition', 'to', 'Lady', 'Antebellum', ',', 'groups', 'such', 'as', 'Herrick', ',', 'The', 'Quebe', 'Sisters', 'Band', ',', 'Little', 'Big', 'Town', ',', 'The', 'Band', 'Perry', ',', 'Gloriana', ',', 'Thompson', 'Square', ',', 'Eli', 'Young', 'Band', ',', 'Zac', 'Brown', 'Band', 'and', 'British', 'duo', 'The', 'Shires', 'have', 'emerged', 'to', 'occupy', 'a', 'large', 'portion', 'of', 'the', 'new', 'country', 'artists', 'in', 'the', 'popular', 'scene', 'along', 'with', 'solo', 'singers', 'Kacey', 'Musgraves', 'and', 'Miranda', 'Lambert', '.']\n",
      "159\n",
      "['Two', 'of', 'his', 'most', 'popular', 'recordings', 'were', 'Layla', ',', 'recorded', 'with', 'Derek', 'and', 'the', 'Dominos', ';', 'and', 'Robert', 'Johnson', \"'\", 's', 'Cross', 'Road', 'Blues', ',', 'recorded', 'with', 'Cream', '.']\n",
      "64\n",
      "['Flood', 'has', 'been', 'certified', 'platinum', 'and', 'their', 'children', \"'s\", 'music', 'albums', 'Here', 'Come', 'the', 'ABCs', ',', 'Here', 'Come', 'the', '123s', ',', 'and', 'Here', 'Comes', 'Science', 'have', 'all', 'been', 'certified', 'gold', '.']\n",
      "70\n",
      "['She', 'is', 'the', 'recipient', 'of', 'various', 'accolades', 'including', 'an', 'Academy', 'Awards', ',', 'three', 'Golden', 'Globe', 'Awards', ',', 'two', 'Critics', \"'\", 'Choice', 'Movie', 'Awards', ',', 'a', 'Screen', 'Actors', 'Guild', 'Award', ',', 'and', 'nominations', 'for', 'four', 'BAFTA', 'Awards', ',', 'three', 'Primetime', 'Emmy', 'Awards', ',', 'and', 'a', 'Grammy', 'Award', '.']\n",
      "118\n",
      "['James', 'Brown', 'is', 'said', 'to', 'be', 'the', 'most', 'sampled', 'artist', 'in', 'the', 'history', 'of', 'hip', 'hop', ',', 'while', 'P-Funk', 'is', 'the', 'second', 'most', 'sampled', 'artist', ';', 'samples', 'of', 'old', 'Parliament', 'and', 'Funkadelic', 'songs', 'formed', 'the', 'basis', 'of', 'West', 'Coast', 'G-funk', '.']\n",
      "98\n",
      "['Her', 'early', 'works', 'in', 'the', '1960s', '(', 'her', 'debut', 'The', 'Barbra', 'Streisand', 'Album', ',', 'The', 'Second', 'Barbra', 'Streisand', 'Album', ',', 'The', 'Third', 'Album', ',', 'My', 'Name', 'Is', 'Barbra', ',', 'etc', '.']\n",
      "74\n",
      "['At', 'these', 'labels', ',', 'Bubbles', 'created', 'more', 'designs', 'for', 'Elvis', 'Costello', ',', 'as', 'well', 'as', 'other', 'artists', 'such', 'as', 'Nick', 'Lowe', ',', 'Carlene', 'Carter', 'and', 'Clive', 'Langer', '&', 'amp', ';', 'The', 'Boxes', '.']\n",
      "78\n",
      "['The', 'band', 'have', 'received', 'a', 'total', 'of', '11', 'nominations', 'for', 'ARIA', 'Music', 'Awards', 'in', 'ARIA', 'Music', 'Awards', 'of', '1999', ',', 'ARIA', 'Music', 'Awards', 'of', '2001', 'and', 'ARIA', 'Music', 'Awards', 'of', '2003', '.']\n",
      "74\n",
      "['Their', 'music', 'has', 'a', 'particular', 'rumba', 'flamenca', 'style', ',', 'with', 'Pop', 'music', 'influences', ';', 'many', 'songs', 'of', 'the', 'Gipsy', 'Kings', 'fit', 'social', 'dance', 's', ',', 'such', 'as', 'salsa', 'and', 'Rhumba', '.']\n",
      "77\n",
      "['Parton', 'received', 'nominations', 'for', 'Drama', 'Desk', 'Award', 'for', 'Outstanding', 'Music', 'and', 'Drama', 'Desk', 'Award', 'for', 'Outstanding', 'Lyrics', ',', 'as', 'well', 'as', 'a', 'nomination', 'for', 'Tony', 'Award', 'for', 'Best', 'Original', 'Score', '.']\n",
      "74\n",
      "['By', 'the', 'end', 'of', 'World', 'War', 'II', ',', 'mountaineer', 'string', 'band', 'music', 'known', 'as', 'Bluegrass', 'music', 'had', 'emerged', 'when', 'Bill', 'Monroe', 'joined', 'with', 'Lester', 'Flatt', 'and', 'Earl', 'Scruggs', ',', 'introduced', 'by', 'Roy', 'Acuff', 'at', 'the', 'Grand', 'Ole', 'Opry', '.']\n",
      "93\n",
      "['At', 'the', '59th', 'Annual', 'Grammy', 'Awards', 'on', '12', 'February', '2017', ',', 'Bowie', 'won', 'all', 'five', 'nominated', 'awards', ':', 'Grammy', 'Award', 'for', 'Best', 'Rock', 'Performance', ';', 'Grammy', 'Award', 'for', 'Best', 'Alternative', 'Music', 'Album', ';', 'Best', 'Engineered', 'Album', ',', 'Non-Classical', ';', 'Grammy', 'Award', 'for', 'Best', 'Recording', 'Package', ';', 'and', 'Grammy', 'Award', 'for', 'Best', 'Rock', 'Song', '.']\n",
      "135\n",
      "['The', 'group', 'has', 'been', 'nominated', 'for', '20', 'Grammy', 'awards', 'and', 'has', 'won', 'five', 'of', 'them', 'with', 'Best', 'Alternative', 'Album', 'for', 'Dookie', ',', 'Best', 'Rock', 'Album', 'for', 'American', 'Idiot', 'and', '21st', 'Century', 'Breakdown', ',', 'Record', 'of', 'the', 'Year', 'for', 'Boulevard', 'of', 'Broken', 'Dreams', ',', 'and', 'Best', 'Musical', 'Show', 'Album', 'for', 'American', 'Idiot', ':', 'The', 'Original', 'Broadway', 'Cast', 'Recording', '.']\n",
      "136\n",
      "['Today', 'there', 'are', 'Celtic-influenced', 'subgenres', 'of', 'virtually', 'every', 'type', 'of', 'popular', 'music', 'including', 'electronica', ',', 'Celtic', 'rock', ',', 'Celtic', 'metal', ',', 'Celtic', 'punk', ',', 'Hip', 'hop', 'music', ',', 'reggae', ',', 'New-age', 'music', ',', 'Latin', ',', 'Andean', 'and', 'Pop', 'music', '.']\n",
      "103\n",
      "['The', 'Righteous', 'Brothers', ',', 'Bobby', 'Hatfield', 'and', 'Bill', 'Medley', ',', 'also', 'guest-starred', 'in', 'different', 'episodes', '.']\n",
      "42\n",
      "['Outside', 'the', 'south', ',', 'the', 'accordion', '(', 'predominantly', 'the', 'piano', 'accordion', ')', 'is', 'used', 'in', 'almost', 'all', 'styles', 'of', 'Forró', '(', 'in', 'particular', 'in', 'the', 'subgenres', 'of', 'Xote', 'and', 'Baião', ')', 'as', 'the', 'principal', 'instrument', ',', 'Luiz', 'Gonzaga', '(', 'the', 'King', 'of', 'the', 'Baião', ')', 'and', 'Dominguinhos', 'being', 'among', 'the', 'notable', 'musicians', 'in', 'this', 'style', 'from', 'the', 'northeast', '.']\n",
      "149\n",
      "['These', 'were', ':', 'Now', 'and', 'Zen', 'in', '1988', ',', 'Manic', 'Nirvana', 'in', '1990', ',', 'and', 'the', '1993', 'Fate', 'of', 'Nations', '(', 'which', 'features', 'Moya', 'Brennan', 'of', 'Clannad', 'and', 'former', 'Cutting', 'Crew', 'guitarist', 'Kevin', 'MacMichael', ')', '.']\n",
      "86\n",
      "['In', 'Finland', ',', 'there', 'emerged', 'a', 'scene', 'that', 'mixed', 'the', 'first', 'wave', 'black', 'metal', 'style', 'with', 'elements', 'of', 'death', 'metal', 'and', 'grindcore', ';', 'this', 'included', 'Beherit', ',', 'Archgoat', 'and', 'Impaled', 'Nazarene', ',', 'whose', 'debut', 'album', 'Tol', 'Cormpt', 'Norz', 'Norz', 'Norz', 'Rock', 'Hard', 'journalist', 'Wolf-Rüdiger', 'Mühlmann', 'considers', 'a', 'part', 'of', 'war', 'metal', \"'s\", 'roots', '.']\n",
      "139\n",
      "['Arguably', 'the', 'most', 'successful', 'boy', 'band', 'manager', 'from', 'the', 'U.S.', 'was', 'Lou', 'Pearlman', ',', 'who', 'founded', 'commercially', 'successful', 'acts', 'such', 'as', 'the', 'Backstreet', 'Boys', 'in', '1993', ',', 'NSYNC', 'and', 'LFO', 'in', '1995', ',', 'O-Town', 'in', '2000', ',', 'and', 'US5', 'in', '2005', '.']\n",
      "101\n",
      "['Extreme', ',', 'Red', 'Hot', 'Chili', 'Peppers', ',', 'Living', 'Colour', ',', 'Jane', \"'s\", 'Addiction', ',', 'Prince', ',', 'Primus', ',', 'Fishbone', ',', 'Faith', 'No', 'More', ',', 'Rage', 'Against', 'the', 'Machine', ',', 'Infectious', 'Grooves', ',', 'and', 'Incubus', 'spread', 'the', 'approach', 'and', 'styles', 'garnered', 'from', 'funk', 'pioneers', 'to', 'new', 'audiences', 'in', 'the', 'mid-to-late', '1980s', 'and', 'the', '1990s', '.']\n",
      "132\n",
      "['Bands', 'like', 'Flogging', 'Molly', ',', 'Black', '47', ',', 'Dropkick', 'Murphys', ',', 'The', 'Young', 'Dubliners', ',', 'The', 'Tossers', 'introduced', 'a', 'hybrid', 'of', 'Celtic', 'rock', ',', 'Punk', 'rock', ',', 'reggae', ',', 'Hardcore', 'punk', 'and', 'other', 'elements', 'in', 'the', '1990s', 'that', 'has', 'become', 'popular', 'with', 'Irish-American', 'youth', '.']\n",
      "113\n",
      "['The', 'Stone', 'Roses', \"'\", 'influences', 'included', 'garage', 'rock', ',', 'electronic', 'dance', 'music', ',', 'Krautrock', ',', 'Northern', 'soul', ',', 'punk', 'rock', ',', 'reggae', ',', 'Soul', 'music', 'and', 'artists', 'such', 'as', 'the', 'Beatles', ',']\n",
      "79\n",
      "['In', '2018', ',', 'Buckingham', 'was', 'fired', 'from', 'the', 'band', 'and', 'was', 'replaced', 'by', 'Mike', 'Campbell', ',', 'formerly', 'of', 'Tom', 'Petty', 'and', 'the', 'Heartbreakers', ',', 'and', 'Neil', 'Finn', 'of', 'Split', 'Enz', 'and', 'Crowded', 'House', '.']\n",
      "78\n",
      "['In', 'Paris', ',', 'he', 'performed', 'at', 'the', 'Stade', 'de', 'France', 'for', 'Saint', 'Patrick', \"'s\", 'Day', ',', 'in', 'AccorHotels', 'Arena', ',', 'the', 'Bataclan', ',', 'the', 'Casino', 'de', 'Paris', 'and', 'the', 'Théâtre', 'de', 'la', 'Ville', 'with', 'guest', 'singers', 'Mari', 'Boine', 'and', 'Karen', 'Matheson', 'as', 'well', 'as', 'Donald', 'Shaw', '.']\n",
      "115\n",
      "['On', '26', 'February', '1987', ',', 'A', 'Hard', 'Day', \"'s\", 'Night', 'was', 'officially', 'released', 'on', 'compact', 'disc', 'in', 'mono', ',', 'along', 'with', 'Please', 'Please', 'Me', ',', 'With', 'the', 'Beatles', ',', 'and', 'Beatles', 'for', 'Sale', '.']\n",
      "74\n",
      "['It', 'started', 'with', 'pop', 'music', 'singers', 'like', 'Glen', 'Campbell', ',', 'Bobbie', 'Gentry', ',', 'John', 'Denver', ',', 'Olivia', 'Newton-John', ',', 'Anne', 'Murray', ',', 'B.', 'J.', 'Thomas', ',', 'The', 'Bellamy', 'Brothers', ',', 'and', 'Linda', 'Ronstadt', 'having', 'hits', 'on', 'the', 'country', 'charts', '.']\n",
      "98\n",
      "['The', 'shows', 'were', 'later', 'taken', 'into', 'Europe', ',', 'and', 'featured', 'such', 'stars', 'as', 'Johnny', 'Cash', ',', 'Dolly', 'Parton', ',', 'Tammy', 'Wynette', ',', 'David', 'Allan', 'Coe', ',', 'Emmylou', 'Harris', ',', 'Boxcar', 'Willie', ',', 'Johnny', 'Russell', 'and', 'Jerry', 'Lee', 'Lewis', '.']\n",
      "92\n",
      "['Arguably', 'the', 'most', 'successful', 'boy', 'band', 'manager', 'from', 'the', 'U.S.', 'was', 'Lou', 'Pearlman', ',', 'who', 'founded', 'commercially', 'successful', 'acts', 'such', 'as', 'the', 'Backstreet', 'Boys', 'in', '1993', ',', 'NSYNC', 'and', 'LFO', 'in', '1995', ',', 'O-Town', 'in', '2000', ',', 'and', 'US5', 'in', '2005', '.']\n",
      "101\n",
      "['In', 'addition', ',', 'the', 'film', 'won', 'the', 'BAFTA', 'Award', 'for', 'Best', 'Film', ',', 'BAFTA', 'Award', 'for', 'Best', 'Direction', '(', 'Nichols', ')', ',', 'BAFTA', 'Award', 'for', 'Most', 'Promising', 'Newcomer', 'to', 'Leading', 'Film', 'Roles', '(', 'Hoffman', ')', ',', 'the', 'BAFTA', 'Award', 'for', 'Best', 'Editing', '(', 'Sam', 'O', \"'Steen\", ')', '.']\n",
      "121\n",
      "['With', 'the', 'influence', 'of', 'Tropicalismo', ',', 'Traditional', 'Samba', 'and', 'Bossa', 'Nova', ',', 'MPB', '(', 'Música', 'popular', 'brasileira', ')', ',', 'or', 'Brazilian', 'Popular', 'Music', ',', 'became', 'highly', 'singer-songwriter', 'based', '.']\n",
      "79\n",
      "['Following', 'the', 'hard', 'rock', 'and', 'heavy', 'metal', 'origins', 'on', 'the', 'band', \"'s\", 'first', 'two', 'albums', ',', 'Too', 'Fast', 'for', 'Love', '(', '1981', ')', 'and', 'Shout', 'at', 'the', 'Devil', '(', '1983', ')', ',', 'the', 'release', 'of', 'its', 'third', 'album', 'Theatre', 'of', 'Pain', '(', '1985', ')', 'saw', 'Mötley', 'Crüe', 'joining', 'the', 'first', 'wave', 'of', 'glam', 'metal', '.']\n",
      "121\n",
      "['In', 'June', '1985', ',', 'the', 'United', 'Way', 'of', 'Canada', 'invited', 'Lata', 'Mangeshkar', 'to', 'perform', 'at', 'Maple', 'Leaf', 'Gardens', '.']\n",
      "48\n",
      "['Soundgarden', 'achieved', 'its', 'biggest', 'success', 'with', 'the', '1994', 'album', 'Superunknown', ',', 'which', 'debuted', 'at', 'number', 'one', 'on', 'the', 'Billboard', '200', 'and', 'yielded', 'the', 'Grammy', 'Award', '-winning', 'singles', 'Spoonman', 'and', 'Black', 'Hole', 'Sun', '.']\n",
      "83\n",
      "['Despite', 'this', ',', 'The', 'Godfather', 'Part', 'III', 'went', 'on', 'to', 'gather', '7', 'Academy', 'Awards', 'nominations', ',', 'including', 'Academy', 'Award', 'for', 'Best', 'Director', 'and', 'Academy', 'Award', 'for', 'Best', 'Picture', '.']\n",
      "71\n",
      "['In', '2005', ',', 'American', 'Idiot', 'won', 'a', 'Grammy', 'Award', 'for', 'Grammy', 'Award', 'for', 'Best', 'Rock', 'Album', 'and', 'was', 'nominated', 'in', 'six', 'other', 'categories', 'including', 'Grammy', 'Award', 'for', 'Album', 'of', 'the', 'Year', '.']\n",
      "78\n",
      "['A', 'sleeper', 'hit', 'in', 'United', 'Kingdom', ',', 'the', 'record', 'eventually', 'hit', 'the', 'top', 'three', 'in', 'the', 'Official', 'Charts', 'Company', 'and', 'received', 'platinum', 'certifications', 'from', 'British', 'Phonographic', 'Industry', ',', 'Recording', 'Industry', 'Association', 'of', 'America', 'and', 'ARIA', '.']\n",
      "85\n",
      "['For', 'the', '2008', '/', '2009', 'season', ',', 'he', 'played', 'Captain', 'Hook', 'at', 'the', 'Milton', 'Keynes', 'Theatre', 'and', 'donned', 'the', 'hook', 'once', 'again', 'for', 'the', '2009', '/', '2010', 'panto', 'season', 'at', 'the', 'Liverpool', 'Empire', 'Theatre', '.']\n",
      "78\n",
      "['The', 'band', 'also', 'released', 'three', 'full-length', 'albums', 'dubbed', '(', 'and', 'later', 'packaged', 'together', 'as', ')', 'The', 'Trilogy', ':', 'The', 'Maggot', ',', 'The', 'Bootlicker', ',', 'and', 'The', 'Crybaby', '.']\n",
      "68\n",
      "['He', 'toured', 'with', 'his', 'band', 'Les', 'Mistigris', '(', 'not', 'related', 'to', 'Mistigris', ')', 'in', 'Germany', ',', 'Belgium', ',', 'France', 'and', 'Turkey', 'until', '1967', '.']\n",
      "55\n",
      "['On', '24', 'August', '2012', ',', 'Westenra', 'staged', 'a', 'concert', 'in', 'the', 'Gŵyl', 'Gobaith', 'Music', 'Festival', 'in', 'Wales', 'to', 'support', 'for', 'charities', 'Cancer', 'Research', 'UK', ',', 'Wales', 'Air', 'Ambulance', ',', 'CLIC', 'Sargent', 'and', 'HeadtoHeart', '.']\n",
      "88\n",
      "['These', 'albums', 'spawned', 'some', 'of', 'Carey', \"'s\", 'most', 'successful', 'singles', ',', 'including', 'Hero', ',', 'Without', 'You', ',', 'All', 'I', 'Want', 'for', 'Christmas', 'Is', 'You', ',', 'Fantasy', ',', 'Always', 'Be', 'My', 'Baby', ',', 'as', 'well', 'as', 'One', 'Sweet', 'Day', ',', 'which', 'peaked', 'at', 'number', 'one', 'in', 'the', 'U.S.', 'for', '16', 'weeks', 'and', 'became', 'Billboard', 's', 'Song', 'Of', 'The', 'Decade', '(', '1990s', 'Decade', ')', '.']\n",
      "141\n",
      "['Michael', 'won', 'various', 'music', 'awards', 'including', 'two', 'Grammy', 'Award', 's', ',', 'three', 'Brit', 'Awards', ',', 'three', 'American', 'Music', 'Award', 's', ',', 'four', 'MTV', 'Video', 'Music', 'Award', 's', 'and', 'six', 'Ivor', 'Novello', 'Awards', '.']\n",
      "79\n",
      "['This', 'style', 'emerged', 'in', 'the', 'United', 'States', 'in', 'the', 'early', 'and', 'mid-1980s', ',', 'with', 'innovators', 'such', 'as', 'Queensrÿche', ',', 'Fates', 'Warning', ',', 'and', 'Dream', 'Theater', '.']\n",
      "65\n",
      "['For', 'Mirrors', ',', 'instead', 'of', 'working', 'with', 'previous', 'producers', 'Sandy', 'Pearlman', '(', 'who', 'instead', 'went', 'on', 'to', 'manage', 'Black', 'Sabbath', ')', 'and', 'Murray', 'Krugman', ',', 'Blue', 'Öyster', 'Cult', 'chose', 'Tom', 'Werman', ',', 'who', 'had', 'worked', 'with', 'acts', 'such', 'as', 'Cheap', 'Trick', 'and', 'Ted', 'Nugent', '.']\n",
      "111\n",
      "['The', 'self-titled', 'record', 'was', 'an', 'instant', 'success', 'both', 'critically', 'and', 'commercially', ',', 'led', 'by', 'the', 'official', 'theme', 'song', 'for', 'UAAP', 'Season', '71', 'of', 'the', 'UAAP', '-', 'Puso', '(', 'trans', ':', 'Heart', ')', '.']\n",
      "77\n",
      "['Examples', 'of', 'such', 'professional', 'groups', 'include', 'Straight', 'No', 'Chaser', ',', 'Pentatonix', ',', 'The', 'House', 'Jacks', ',', 'Rockapella', ',', 'Mosaic', ',', 'Home', 'Free', 'and', 'M-pact', '.']\n",
      "63\n",
      "['Simon', 'has', 'won', '12', 'Grammy', 'Award', 's', '(', 'one', 'of', 'them', 'a', 'Grammy', 'Lifetime', 'Achievement', 'Award', ')', 'and', 'five', 'Grammy', 'Award', 'for', 'Album', 'of', 'the', 'Year', 'Grammy', 'nominations', ',', 'the', 'most', 'recent', 'for', 'You', \"'re\", 'the', 'One', 'in', '2001', '.']\n",
      "98\n",
      "['Brazil', 'Classics', '!', '--', 'redirects', 'here', '--', ',', 'the', 'label', \"'s\", 'first', 'compilation', 'series', ',', 'consists', 'of', 'seven', 'albums', 'surveying', 'genres', 'ranging', 'from', 'Samba', 'to', 'Tropicália', ',', 'as', 'well', 'as', 'individual', 'artists', '.']\n",
      "81\n",
      "['In', 'addition', ',', 'a', 'vintage', 'siren', ',', 'just', 'as', 'the', 'original', 'Boston', 'Garden', 'had', 'used', ',', 'was', 'added', 'to', 'replace', 'the', 'end-of-period', 'horn', 'for', 'hockey', 'only', ',', 'a', 'feature', 'of', 'the', 'Montreal', 'Canadiens', ',', 'the', 'Bruins', \"'\", 'arch-rivals', ',', 'at', 'the', 'Montreal', 'Forum', '(', 'now', 'the', 'Pepsi', 'Forum', 'shopping', 'centre', ')', 'and', 'the', 'current', 'Bell', 'Centre', '.']\n",
      "139\n",
      "['This', 'was', 'followed', 'by', 'a', 'series', 'of', 'small', ',', 'intimate', 'gigs', 'at', 'UK', 'venues', 'such', 'as', 'Liverpool', \"'s\", 'The', 'Cavern', 'Club', ',', 'London', \"'s\", 'Mean', 'Fiddler', ',', 'and', 'Glasgow', \"'s\", 'Barrowland', 'Ballroom', '.']\n",
      "78\n",
      "['Attracting', 'over', '200,000', 'fans', ',', 'Black', 'Sabbath', 'appeared', 'alongside', 'popular', '1970s', 'rock', 'and', 'pop', 'bands', 'Deep', 'Purple', ',', 'Eagles', ',', 'Emerson', ',', 'Lake', '&', 'Palmer', ',', 'Rare', 'Earth', ',', 'Seals', 'and', 'Crofts', ',', 'Black', 'Oak', 'Arkansas', ',', 'and', 'Earth', ',', 'Wind', '&', 'Fire', '.']\n",
      "105\n",
      "['Staind', 'has', 'recorded', 'seven', 'studio', 'albums', ':', 'Tormented', '(', '1996', ')', ',', 'Dysfunction', '(', '1999', ')', ',', 'Break', 'the', 'Cycle', '(', '2001', ')', ',', '14', 'Shades', 'of', 'Grey', '(', '2003', ')', ',', 'Chapter', 'V', '(', '2005', ')', ',', 'The', 'Illusion', 'of', 'Progress', '(', '2008', ')', ',', 'and', 'Staind', '(', '2011', ')', '.']\n",
      "116\n",
      "['Following', 'the', 'end', 'of', 'Nirvana', ',', 'Novoselic', 'worked', 'on', 'completing', 'the', 'With', 'the', 'Lights', 'Out', 'box', 'set', 'and', 'From', 'the', 'Muddy', 'Banks', 'of', 'the', 'Wishkah', 'album', ',', 'as', 'well', 'as', 'pushing', 'for', 'release', 'of', 'a', 'Nevermind', '.']\n",
      "87\n",
      "['However', ',', 'some', 'bands', 'were', 'created', 'around', 'the', 'talent', 'of', 'a', 'songwriter', 'within', 'the', 'group', 'like', 'Gary', 'Barlow', 'of', 'Take', 'That', 'or', 'Tony', 'Mortimer', 'of', 'East', '17', '.']\n",
      "62\n",
      "['Since', 'then', 'the', 'band', 'have', 'released', 'five', 'albums', ':', 'In', 'It', 'for', 'the', 'Money', '(', '1997', ')', ',', 'Supergrass', '(', '1999', ')', ',', 'Life', 'on', 'Other', 'Planets', '(', '2002', ')', ',', 'Road', 'to', 'Rouen', '(', '2005', ')', 'and', 'Diamond', 'Hoo', 'Ha', '(', '2008', ')', ',', 'as', 'well', 'as', 'a', 'decade-ending', 'compilation', 'called', 'Supergrass', 'Is', '10', '(', '2004', ')', '.']\n",
      "129\n",
      "['At', 'the', '33rd', 'Academy', 'Awards', ',', 'The', 'Apartment', 'was', 'nominated', 'for', 'ten', 'awards', 'and', 'won', 'five', ',', 'including', 'Academy', 'Award', 'for', 'Best', 'Picture', ',', 'Academy', 'Award', 'for', 'Best', 'Director', ',', 'and', 'Academy', 'Award', 'for', 'Best', 'Original', 'Screenplay', '.']\n",
      "93\n",
      "['Dream', 'On', ',', 'I', 'Feel', 'Loved', ',', 'Freelove', 'and', 'Goodnight', 'Lovers', 'were', 'released', 'as', 'singles', 'in', '2001', 'and', '2002', '.']\n",
      "46\n",
      "['He', 'has', 'musically', 'encompassed', 'Folk', 'music', ',', 'funk', ',', 'Soul', 'music', ',', 'Hip', 'hop', 'music', ',', 'Electronic', 'music', ',', 'alternative', 'rock', ',', 'Country', 'music', ',', 'and', 'psychedelia', '.']\n",
      "66\n",
      "['Coldcut', 'returned', 'with', 'the', 'single', 'Everything', 'Is', 'Under', 'Control', 'at', 'the', 'end', 'of', '2005', ',', 'featuring', 'Jon', 'Spencer', '(', 'of', 'Jon', 'Spencer', 'Blues', 'Explosion', ')', 'and', 'Mike', 'Ladd', '.']\n",
      "68\n",
      "['The', 'series', 'featured', 'five', 'albums', 'of', 'Masada', 'themes', 'including', 'Masada', 'Guitars', 'by', 'Marc', 'Ribot', ',', 'Bill', 'Frisell', ',', 'and', 'Tim', 'Sparks', ';', 'Masada', 'Recital', 'by', 'Mark', 'Feldman', 'and', 'Sylvie', 'Courvoisier', ';', 'Masada', 'Rock', 'by', 'Rashanim', ';', 'and', 'two', 'albums', 'featuring', 'various', 'artists', ',', 'Voices', 'in', 'the', 'Wilderness', 'and', 'The', 'Unknown', 'Masada', '.']\n",
      "137\n",
      "['Depeche', 'Mode', 'contributed', 'their', 'cover', 'of', 'the', 'U2', 'song', 'So', 'Cruel', 'to', 'the', 'tribute', 'album', 'AHK-toong', 'BAY-bi', 'Covered', 'honouring', 'the', '20th', 'anniversary', 'of', 'Achtung', 'Baby', ',', 'a', '1991', 'album', 'by', 'U2', '.']\n",
      "84\n",
      "['The', 'stadium', 'also', 'hosted', 'such', 'events', 'as', '1973', 'Summer', 'Universiade', ',', '1986', 'Goodwill', 'Games', 'and', '2013', 'World', 'Championships', 'in', 'Athletics', '.']\n",
      "53\n",
      "['In', '1995', ',', 'Dookie', 'won', 'the', 'Grammy', 'Award', 'for', 'Grammy', 'Award', 'for', 'Best', 'Alternative', 'Music', 'Album', 'and', 'the', 'band', 'was', 'nominated', 'for', 'nine', 'MTV', 'Video', 'Music', 'Award', 's', 'including', 'Video', 'of', 'the', 'Year', '.']\n",
      "79\n",
      "['He', 'also', 'became', 'progressively', 'more', 'involved', 'with', 'Irish-American', 'organizations', ':', 'in', '1908', 'he', 'joined', 'the', 'Friendly', 'Sons', 'of', 'St.', 'Patrick', '(', 'becoming', 'president', 'in', '1916', ')', ',', 'the', 'oldest', 'Irish', 'association', 'in', 'New', 'York', ',', 'and', 'in', '1911', 'he', 'became', 'a', 'member', 'of', 'the', 'American', 'Irish', 'Historical', 'Society', '.']\n",
      "115\n",
      "['The', 'Benedictines', 'and', 'their', 'offshoots', '(', 'Cistercians', 'and', 'Trappists', 'among', 'them', ')', ',', 'the', 'Premonstratensians', ',', 'and', 'the', 'military', 'orders', 'distinguish', 'between', 'conventual', 'and', 'simple', 'or', 'obedientiary', 'priories', '.']\n",
      "80\n",
      "['Poland', 'has', 'always', 'been', 'a', 'very', 'open', 'country', 'to', 'new', 'music', 'genres', 'and', 'even', 'before', 'the', 'fall', 'of', 'the', 'communism', ',', 'music', 'styles', 'like', 'rock', ',', 'Heavy', 'metal', 'music', ',', 'jazz', ',', 'Electronic', 'music', ',', 'and', 'New', 'wave', 'music', 'were', 'well-known', '.']\n",
      "91\n",
      "['Blues', 'subgenres', 'include', 'country', 'blues', ',', 'such', 'as', 'Delta', 'blues', 'and', 'Piedmont', 'blues', ',', 'as', 'well', 'as', 'urban', 'blues', 'styles', 'such', 'as', 'Chicago', 'blues', 'and', 'West', 'Coast', 'blues', '.']\n",
      "70\n",
      "['The', 'musical', 'was', 'an', 'immediate', 'hit', ',', 'winning', 'Tony', 'Award', 's', 'for', 'Tony', 'Award', 'for', 'Best', 'Musical', ',', 'Tony', 'Award', 'for', 'Best', 'Actress', 'in', 'a', 'Musical', '(', 'for', 'Lawrence', ')', 'and', 'Tony', 'Award', 'for', 'Best', 'Featured', 'Actor', 'in', 'a', 'Musical', '(', 'for', 'Brynner', ')', '.']\n",
      "103\n",
      "['In', '1995', ',', 'Nas', 'did', 'guest', 'performances', 'on', 'the', 'albums', 'Doe', 'or', 'Die', 'by', 'AZ', ',', 'The', 'Infamous', 'by', 'Mobb', 'Deep', ',', 'Only', 'Built', '4', 'Cuban', 'Linx', 'by', 'Raekwon', 'and', '4,5,6', 'by', 'Kool', 'G', 'Rap', '.']\n",
      "89\n",
      "['In', '1995', ',', 'he', 'guested', 'on', 'two', 'tracks', 'on', 'Tom', 'Cochrane', \"'\", 's', 'Ragged', 'Ass', 'Road', 'album', 'and', 'then', 'in', '1996', 'on', 'I', 'Mother', 'Earth', \"'\", 's', 'Like', 'a', 'Girl', 'from', 'the', 'Scenery', 'and', 'Fish', 'album', '.']\n",
      "79\n",
      "['She', 'released', 'her', 'first', 'Spanish', 'language', 'album', ',', 'Mi', 'Plan', ',', 'in', '2009', ',', 'which', 'won', 'her', 'a', 'Latin', 'Grammy', 'Award', 'for', 'Latin', 'Grammy', 'Award', 'for', 'Best', 'Female', 'Pop', 'Vocal', 'Album', '.']\n",
      "72\n",
      "['Bands', 'sponsored', 'by', 'factories', 'include', 'The', 'Black', 'Dyke', 'Mills', 'Band', ',', 'Yorkshire', 'Imperial', 'Band', '(', 'originally', 'the', 'Yorkshire', 'Copperworks', 'Band', ')', ',', 'Foden', \"'s\", 'sponsored', 'by', 'the', 'truck', 'manufacturer', ',', 'Fairey', 'Band', 'sponsored', 'by', 'the', 'aircraft', 'manufacturer', ',', 'and', 'Leyland', 'Band', 'sponsored', 'by', 'the', 'vehicle', 'manufacturer', '.']\n",
      "117\n",
      "['He', 'has', 'been', 'involved', 'in', 'charitable', 'work', ',', 'including', 'ONE', 'Campaign', ',', 'H2O', 'Africa', 'Foundation', ',', 'Feeding', 'America', ',', 'and', 'Water.org', '.']\n",
      "52\n",
      "['Prestwich', 'joined', 'Little', 'River', 'Band', 'in', '1984', 'and', 'appeared', 'on', 'the', 'albums', ',', 'Playing', 'to', 'Win', 'and', 'No', 'Reins', ',', 'before', 'departing', 'in', '1986', 'to', 'join', 'Farnham', \"'s\", 'touring', 'band', '.']\n",
      "72\n",
      "['Their', 'debut', 'album', 'The', 'Magnificent', 'Moodies', ',', 'produced', 'by', 'Denny', 'Cordell', 'with', 'a', 'strong', 'Beat', 'music', '/', 'Rhythm', 'and', 'blues', 'flavour', ',', 'was', 'released', 'on', 'Decca', 'in', 'mono', 'only', 'in', '1965', '.']\n",
      "76\n",
      "['According', 'to', 'the', 'band', \"'s\", 'biographer', 'Dave', 'Lewis', ',', 'while', 'the', 'barnstorming', 'effect', 'of', 'the', 'early', 'era', 'was', 'now', 'levelling', 'off', ',', 'and', 'though', 'devoid', 'of', 'the', 'electricity', 'of', 'Zeppelin', 'I', 'and', 'Led', 'Zeppelin', 'II', ',', 'the', 'sheer', 'diversity', 'of', 'Led', 'Zeppelin', 'III', ',', 'and', 'lacking', 'the', 'classic', 'status', 'of', 'Led', 'Zeppelin', 'IV', ',', 'Houses', 'of', 'the', 'Holy', 'nevertheless', 'found', 'its', 'rightful', 'niche', '.']\n",
      "147\n",
      "['In', '1961', ',', 'he', 'performed', 'ten', 'recitals', 'in', 'Carnegie', 'Hall', 'to', 'raise', 'roughly', '$', '100,000', 'for', 'charities', 'including', 'Big', 'Brothers', 'Big', 'Sisters', 'of', 'America', ',', 'United', 'Jewish', 'Appeal', ',', 'Polish', 'Assistance', ',', 'Musicians', 'Emergency', 'fund', ',', 'the', 'National', 'Association', 'for', 'Mental', 'Health', ',', 'and', 'the', 'Legal', 'Defense', 'Fund', 'of', 'the', 'National', 'Advancement', 'of', 'Colored', 'People', '.']\n",
      "131\n",
      "['Today', ',', 'musicians', 'as', 'diverse', 'as', 'Keith', 'Urban', ',', 'Rod', 'Stewart', ',', 'Taj', 'Mahal', ',', 'Joe', 'Satriani', ',', 'David', 'Hidalgo', ',', 'Larry', 'Lalonde', 'and', 'Doc', 'Watson', 'play', 'the', 'six-string', 'guitar', 'banjo', '.']\n",
      "81\n",
      "['The', 'initial', 'volume', 'of', 'the', 'album', 'set', '(', 'Anthology', '1', ')', 'was', 'released', 'the', 'same', 'week', 'of', 'the', 'documentary', \"'s\", 'airdate', ',', 'with', 'the', 'subsequent', 'two', 'volumes', '(', 'Anthology', '2', 'and', 'Anthology', '3', ')', 'released', 'in', '1996', '.']\n",
      "83\n",
      "['International', 'who', \"'s\", 'who', 'in', 'popular', 'music', ',', 'Volume', '4', 'p.37.', 'Routledge', ',', '2002', 'The', 'band', 'was', 'renamed', 'Rocket', 'Baby', 'Dolls', 'and', 'adopted', 'a', 'Gothic', 'rock', '-', 'Glam', 'rock', 'image', '.']\n",
      "73\n",
      "['In', 'September', '2007', ',', 'Boney', 'M.', \"'\", 's', 'last', 'four', 'original', 'albums', ',', 'Boonoonoonoos', ',', 'Ten', 'Thousand', 'Lightyears', ',', 'Kalimba', 'de', 'Luna', '-', '16', 'Happy', 'Songs', 'and', 'Eye', 'Dance', 'were', 'reissued', 'on', 'compact', 'disc', 'in', 'Europe', 'and', 'the', 'United', 'States', ',', 'all', 'including', 'bonus', 'tracks', '.']\n",
      "109\n",
      "['Despite', 'the', 'appeal', 'of', 'the', 'Nashville', 'sound', ',', 'many', 'traditional', 'country', 'artists', 'emerged', 'during', 'this', 'period', 'and', 'dominated', 'the', 'genre', ':', 'Loretta', 'Lynn', ',', 'Merle', 'Haggard', ',', 'Buck', 'Owens', ',', 'Porter', 'Wagoner', ',', 'George', 'Jones', ',', 'and', 'Sonny', 'James', 'among', 'them', '.']\n",
      "102\n",
      "['Christian', 'alternative', 'music', 'has', 'its', 'roots', 'in', 'the', 'early', '1980s', ',', 'as', 'the', 'earliest', 'efforts', 'at', 'Christian', 'punk', 'and', 'new', 'wave', 'were', 'recorded', 'by', 'artists', 'like', 'Andy', 'McCarroll', 'and', 'Moral', 'Support', ',', 'Undercover', ',', 'the', '77s', ',', 'Steve', 'Scott', ',', 'Adam', 'Again', ',', 'Quickflight', ',', 'Daniel', 'Amos', ',', 'Youth', 'Choir', '(', 'later', 'renamed', 'the', 'Choir', ')', ',', 'Lifesavers', 'Underground', ',', 'Michael', 'Knott', ',', 'the', 'Prayer', 'Chain', ',', 'Altar', 'Boys', ',', 'Breakfast', 'with', 'Amy', ',', 'Steve', 'Taylor', ',', '4-4-1', ',', 'David', 'Edwards', 'and', 'Vector', '.']\n",
      "199\n",
      "['He', 'has', 'won', 'numerous', 'accolades', 'for', 'his', 'work', ',', 'including', 'an', 'Academy', 'Award', 'for', 'Best', 'Adapted', 'Screenplay', ',', 'a', 'Student', 'Academy', 'Award', ',', 'a', 'BAFTA', 'Award', 'for', 'Best', 'Adapted', 'Screenplay', ',', 'two', 'Emmy', 'Awards', ',', 'two', 'Peabody', 'Award', 's', ',', 'and', 'the', 'Cannes', 'Grand', 'Prix', '.']\n",
      "116\n",
      "['The', 'mid', '2000s', ',', 'especially', 'the', 'United', 'Kingdom', 'and', 'the', 'rest', 'of', 'Europe', ',', 'saw', 'the', 'continued', 'longevity', 'of', 'nineties', 'boy', 'bands', 'such', 'as', 'Backstreet', 'Boys', 'and', 'Westlife', '(', 'before', 'they', 'disbanded', 'in', '2012', ')', ',', 'and', 'the', 'successful', 'comeback', 'of', 'Take', 'That', 'in', '2005', ',', 'Boyzone', 'in', '2007', ',', 'and', 'New', 'Kids', 'on', 'the', 'Block', 'in', '2008', '.']\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "n_tokens_per_sample = []\n",
    "for sample in dataset_dict[\"train\"]:\n",
    "    print(sample[\"tokens\"])\n",
    "    tokenized_examples = tokenizer(\n",
    "        sample[\"tokens\"],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=MAX_SEQ_LENGTH,\n",
    "        stride=DOC_STRIDE,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    input_ids = tokenized_examples['input_ids']\n",
    "    input_ids = np.where(np.array(input_ids) > 1, input_ids, 0)\n",
    "    print(np.count_nonzero(input_ids))\n",
    "    n_tokens_per_sample.append(np.count_nonzero(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "93.59\n"
     ]
    }
   ],
   "source": [
    "max_n_tokens_per_sample = np.max(np.array(n_tokens_per_sample))\n",
    "print(max_n_tokens_per_sample)\n",
    "average_n_tokens_per_sample = np.average(np.array(n_tokens_per_sample))\n",
    "print(average_n_tokens_per_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album': 'A music album is a collection of audio recordings, typically songs, that are released together as a single package. Which are albums in the document ?', 'award': 'A music award is like a prize given to musicians or groups to acknowledge their achievements in areas like singing, writing music, and producing. Which are awards in the document ?', 'band': 'A music band is a group of musicians who play instruments and/or sing together. Which are bands in the document ?', 'country': 'A country is a distinct geographical area with its own government, borders, and population. Which are countries in the document ?', 'event': 'An event is a planned and organized occasion or happening, often with a specific purpose or goal, where people gather to participate or observe. Which are events in the document ?', 'location': 'A location is a specific place or position, usually defined by its geographical coordinates, where something exists or events occur. Which are locations in the document ?', 'misc': 'Apart from albums, awards, bands, countries, events, locations, musical artists, musical instruments, music genres, organisations, people and songs, which are other relevant information in the document ?', 'musicalartist': 'A musical artist is an individual involved in creating, performing, and often composing music. Which are musical artists in the document ?', 'musicalinstrument': 'A musical instrument is a tool or device to make music. Which are musical instruments in the document ?', 'musicgenre': 'A music genre is a category that classifies music based on shared characteristics, such as musical style, cultural influences, and thematic elements. Which are genres in the document ?', 'organisation': 'An organization is a structured group of people with a common goal, purpose, or function, often working together to achieve specific objectives. Which are organisations in the document ?', 'person': 'A person is an individual human being. Which are person but not musical artists in the document ?', 'song': 'A song is a musical composition typically consisting of lyrics and melody, often intended for singing or performance. Which are songs in the document ?'}\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['doc_question_pairID', 'document_context', 'tagName', 'question', 'answers'],\n",
      "        num_rows: 1300\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['doc_question_pairID', 'document_context', 'tagName', 'question', 'answers'],\n",
      "        num_rows: 4940\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['doc_question_pairID', 'document_context', 'tagName', 'question', 'answers'],\n",
      "        num_rows: 6045\n",
      "    })\n",
      "    dataset_name: music\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset_QA_format = data_handler_cross_NER.build_dataset_QA_format(dataset_dict, path_to_questions)\n",
    "print(dataset_QA_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003 World Championships in Athletics\n",
      "6\n",
      "Stade de France\n",
      "5\n",
      "PUSA\n",
      "3\n",
      "U.S.\n",
      "5\n",
      "Canada\n",
      "2\n",
      "Australia\n",
      "2\n",
      "New Zealand\n",
      "3\n",
      "Japan\n",
      "2\n",
      "Europe\n",
      "2\n",
      "the Specials\n",
      "4\n",
      "Ghost Town\n",
      "3\n",
      "Squeeze\n",
      "4\n",
      "Fun Boy Three\n",
      "4\n",
      "Elvis Costello\n",
      "5\n",
      "Barney Bubbles\n",
      "5\n",
      "Is That Love\n",
      "4\n",
      "Tempted\n",
      "4\n",
      "Clubland\n",
      "3\n",
      "New Lace Sleeves\n",
      "7\n",
      "The Lunatics ( Have Taken Over the Asylum )\n",
      "11\n",
      "United States\n",
      "3\n",
      "United Kingdom\n",
      "3\n",
      "Germany\n",
      "2\n",
      "Ireland\n",
      "2\n",
      "Poland\n",
      "3\n",
      "Australia\n",
      "2\n",
      "European\n",
      "2\n",
      "Sacred Harp\n",
      "5\n",
      "Backstreet Boys\n",
      "4\n",
      "Spice Girls\n",
      "4\n",
      "Madonna\n",
      "3\n",
      "Debbie Gibson\n",
      "4\n",
      "Tiffany\n",
      "4\n",
      "Sun Ra Visits Planet Earth\n",
      "7\n",
      "Interstellar Low Ways\n",
      "5\n",
      "Super-Sonic Jazz\n",
      "6\n",
      "We Travel the Space Ways\n",
      "6\n",
      "The Nubians of Plutonia\n",
      "9\n",
      "Jazz In Silhouette\n",
      "7\n",
      "Sun Ra\n",
      "3\n",
      "Tea for the Tillerman\n",
      "6\n",
      "Teaser and the Firecat\n",
      "7\n",
      "US\n",
      "2\n",
      "Stevens\n",
      "3\n",
      "Recording Industry Association of America\n",
      "7\n",
      "BBC News\n",
      "3\n",
      "Top New Male Vocalist\n",
      "7\n",
      "Vocal Event of the Year\n",
      "7\n",
      "Billboard\n",
      "3\n",
      "Academy of Country Music\n",
      "7\n",
      "Country Music Association\n",
      "4\n",
      "Power in Black\n",
      "4\n",
      "Exodus\n",
      "3\n",
      "Testament\n",
      "3\n",
      "Bay Area\n",
      "3\n",
      "Verni\n",
      "4\n",
      "Skates\n",
      "3\n",
      "Ellsworth\n",
      "3\n",
      "Gustafson\n",
      "5\n",
      "thrash metal\n",
      "5\n",
      "Rock and roll\n",
      "4\n",
      "Punk rock\n",
      "4\n",
      "Dr. Dre Presents the Aftermath\n",
      "8\n",
      "The Psycho Realm\n",
      "4\n",
      "Psycho Realm\n",
      "4\n",
      "RBX\n",
      "3\n",
      "Nas\n",
      "3\n",
      "KRS-One\n",
      "5\n",
      "Dr. Dre\n",
      "4\n",
      "East Coast Killer\n",
      "4\n",
      "West Coast Killer\n",
      "4\n",
      "Paris\n",
      "2\n",
      "Théâtre de la Ville\n",
      "9\n",
      "Les Troyens à Carthage\n",
      "7\n",
      "Didon\n",
      "3\n",
      "Énée\n",
      "4\n",
      "Marie Delna\n",
      "4\n",
      "Jules Danbé\n",
      "6\n",
      "Opéra-Comique\n",
      "7\n",
      "Stéphane Lafarge\n",
      "7\n",
      "Brit Awards\n",
      "3\n",
      "American Music Awards\n",
      "4\n",
      "MTV Europe Music Awards\n",
      "6\n",
      "MTV Video Music Award\n",
      "6\n",
      "World Music Awards\n",
      "4\n",
      "Spice Girls\n",
      "4\n",
      "Billboard\n",
      "3\n",
      "contemporary R & B\n",
      "6\n",
      "deep house\n",
      "3\n",
      "Swing music\n",
      "4\n",
      "Hip hop music\n",
      "5\n",
      "Rock music\n",
      "3\n",
      "Pop music\n",
      "3\n",
      "Chuck Burgi\n",
      "4\n",
      "John Miceli\n",
      "4\n",
      "John O 'Reilly\n",
      "5\n",
      "Bobby Rondinelli\n",
      "6\n",
      "Lady Antebellum\n",
      "6\n",
      "Herrick\n",
      "3\n",
      "The Quebe Sisters Band\n",
      "6\n",
      "Little Big Town\n",
      "4\n",
      "The Band Perry\n",
      "4\n",
      "Gloriana\n",
      "4\n",
      "Thompson Square\n",
      "3\n",
      "Eli Young Band\n",
      "5\n",
      "Zac Brown Band\n",
      "5\n",
      "The Shires\n",
      "4\n",
      "British duo\n",
      "3\n",
      "Kacey Musgraves\n",
      "6\n",
      "Miranda Lambert\n",
      "4\n",
      "country\n",
      "2\n",
      "Derek and the Dominos\n",
      "7\n",
      "Cream\n",
      "3\n",
      "Robert Johnson\n",
      "3\n",
      "Layla\n",
      "3\n",
      "Cross Road Blues\n",
      "4\n",
      "Flood\n",
      "3\n",
      "Here Come the ABCs\n",
      "6\n",
      "Here Come the 123s\n",
      "6\n",
      "Here Comes Science\n",
      "4\n",
      "Academy Awards\n",
      "5\n",
      "Golden Globe Awards\n",
      "4\n",
      "Critics ' Choice Movie Awards\n",
      "6\n",
      "Screen Actors Guild Award\n",
      "6\n",
      "BAFTA Awards\n",
      "5\n",
      "Primetime Emmy Awards\n",
      "5\n",
      "Grammy Award\n",
      "5\n",
      "P-Funk\n",
      "5\n",
      "Parliament and Funkadelic\n",
      "7\n",
      "James Brown\n",
      "3\n",
      "hip hop\n",
      "3\n",
      "West Coast G-funk\n",
      "7\n",
      "The Barbra Streisand Album\n",
      "8\n",
      "The Second Barbra Streisand Album\n",
      "9\n",
      "The Third Album\n",
      "4\n",
      "My Name Is Barbra\n",
      "6\n",
      "Clive Langer & amp ; The Boxes\n",
      "11\n",
      "Elvis Costello\n",
      "5\n",
      "Nick Lowe\n",
      "3\n",
      "Carlene Carter\n",
      "4\n",
      "Bubbles\n",
      "4\n",
      "ARIA Music Awards\n",
      "5\n",
      "ARIA Music Awards of 1999\n",
      "7\n",
      "ARIA Music Awards of 2001\n",
      "7\n",
      "ARIA Music Awards of 2003\n",
      "7\n",
      "Gipsy Kings\n",
      "5\n",
      "rumba flamenca\n",
      "7\n",
      "Pop music\n",
      "3\n",
      "salsa\n",
      "3\n",
      "Rhumba\n",
      "4\n",
      "Drama Desk Award for Outstanding Music\n",
      "9\n",
      "Drama Desk Award for Outstanding Lyrics\n",
      "10\n",
      "Tony Award for Best Original Score\n",
      "7\n",
      "Parton\n",
      "3\n",
      "World War II\n",
      "4\n",
      "Grand Ole Opry\n",
      "5\n",
      "Bill Monroe\n",
      "3\n",
      "Lester Flatt\n",
      "5\n",
      "Earl Scruggs\n",
      "7\n",
      "Roy Acuff\n",
      "4\n",
      "Bluegrass music\n",
      "4\n",
      "59th Annual Grammy Awards\n",
      "6\n",
      "Grammy Award for Best Rock Performance\n",
      "9\n",
      "Grammy Award for Best Alternative Music Album\n",
      "10\n",
      "Best Engineered Album , Non-Classical\n",
      "10\n",
      "Grammy Award for Best Recording Package\n",
      "9\n",
      "Grammy Award for Best Rock Song\n",
      "9\n",
      "Bowie\n",
      "3\n",
      "Dookie\n",
      "3\n",
      "American Idiot\n",
      "4\n",
      "21st Century Breakdown\n",
      "6\n",
      "Boulevard of Broken Dreams\n",
      "7\n",
      "American Idiot\n",
      "4\n",
      "The Original Broadway Cast Recording\n",
      "6\n",
      "Grammy awards\n",
      "5\n",
      "Best Alternative Album\n",
      "4\n",
      "Best Rock Album\n",
      "4\n",
      "Record of the Year\n",
      "5\n",
      "Best Musical Show Album\n",
      "5\n",
      "electronica\n",
      "4\n",
      "Celtic rock\n",
      "5\n",
      "Celtic metal\n",
      "5\n",
      "Celtic punk\n",
      "5\n",
      "Hip hop music\n",
      "5\n",
      "reggae\n",
      "4\n",
      "New-age music\n",
      "5\n",
      "Latin\n",
      "2\n",
      "Andean\n",
      "3\n",
      "Pop music\n",
      "3\n",
      "The Righteous Brothers\n",
      "5\n",
      "Bobby Hatfield\n",
      "5\n",
      "Bill Medley\n",
      "4\n",
      "King of the Baião\n",
      "6\n",
      "Luiz Gonzaga\n",
      "5\n",
      "Dominguinhos\n",
      "6\n",
      "piano accordion\n",
      "5\n",
      "Forró\n",
      "4\n",
      "Xote\n",
      "3\n",
      "Baião\n",
      "4\n",
      "Now and Zen\n",
      "4\n",
      "Manic Nirvana\n",
      "4\n",
      "Fate of Nations\n",
      "5\n",
      "Clannad\n",
      "4\n",
      "Cutting Crew\n",
      "4\n",
      "Moya Brennan\n",
      "4\n",
      "Kevin MacMichael\n",
      "4\n",
      "Tol Cormpt Norz Norz Norz\n",
      "11\n",
      "Rock Hard\n",
      "3\n",
      "Beherit\n",
      "4\n",
      "Archgoat\n",
      "4\n",
      "Impaled Nazarene\n",
      "6\n",
      "Finland\n",
      "3\n",
      "black metal\n",
      "3\n",
      "death metal\n",
      "3\n",
      "grindcore\n",
      "4\n",
      "war metal\n",
      "3\n",
      "Wolf-Rüdiger Mühlmann\n",
      "10\n",
      "Backstreet Boys\n",
      "4\n",
      "NSYNC\n",
      "4\n",
      "LFO\n",
      "3\n",
      "O-Town\n",
      "4\n",
      "US5\n",
      "3\n",
      "U.S.\n",
      "5\n",
      "Lou Pearlman\n",
      "4\n",
      "Extreme\n",
      "2\n",
      "Red Hot Chili Peppers\n",
      "6\n",
      "Living Colour\n",
      "3\n",
      "Jane 's Addiction\n",
      "5\n",
      "Primus\n",
      "3\n",
      "Fishbone\n",
      "3\n",
      "Faith No More\n",
      "4\n",
      "Rage Against the Machine\n",
      "6\n",
      "Infectious Grooves\n",
      "6\n",
      "Incubus\n",
      "4\n",
      "funk\n",
      "3\n",
      "Prince\n",
      "2\n",
      "Flogging Molly\n",
      "5\n",
      "Black 47\n",
      "3\n",
      "Dropkick Murphys\n",
      "5\n",
      "The Young Dubliners\n",
      "5\n",
      "The Tossers\n",
      "5\n",
      "Irish-American\n",
      "4\n",
      "Celtic rock\n",
      "5\n",
      "Punk rock\n",
      "4\n",
      "reggae\n",
      "4\n",
      "Hardcore punk\n",
      "4\n",
      "The Stone Roses\n",
      "4\n",
      "the Beatles\n",
      "3\n",
      "garage rock\n",
      "4\n",
      "electronic dance music\n",
      "5\n",
      "Krautrock\n",
      "5\n",
      "Northern soul\n",
      "3\n",
      "punk rock\n",
      "3\n",
      "reggae\n",
      "4\n",
      "Soul music\n",
      "3\n",
      "Tom Petty and the Heartbreakers\n",
      "7\n",
      "Split Enz\n",
      "4\n",
      "Crowded House\n",
      "5\n",
      "Buckingham\n",
      "4\n",
      "Mike Campbell\n",
      "3\n",
      "Neil Finn\n",
      "3\n",
      "Saint Patrick 's Day\n",
      "6\n",
      "Paris\n",
      "2\n",
      "Stade de France\n",
      "5\n",
      "AccorHotels Arena\n",
      "6\n",
      "Bataclan\n",
      "4\n",
      "Casino de Paris\n",
      "5\n",
      "Théâtre de la Ville\n",
      "9\n",
      "Mari Boine\n",
      "5\n",
      "Karen Matheson\n",
      "6\n",
      "Donald Shaw\n",
      "3\n",
      "Hard Day 's Night\n",
      "6\n",
      "Please Please Me\n",
      "4\n",
      "With the Beatles\n",
      "4\n",
      "Beatles for Sale\n",
      "5\n",
      "The Bellamy Brothers\n",
      "5\n",
      "Anne Murray\n",
      "3\n",
      "B. J. Thomas\n",
      "6\n",
      "Linda Ronstadt\n",
      "5\n",
      "pop music\n",
      "3\n",
      "Glen Campbell\n",
      "4\n",
      "Bobbie Gentry\n",
      "5\n",
      "John Denver\n",
      "3\n",
      "Olivia Newton-John\n",
      "7\n",
      "Europe\n",
      "2\n",
      "Johnny Cash\n",
      "3\n",
      "Dolly Parton\n",
      "5\n",
      "Tammy Wynette\n",
      "5\n",
      "David Allan Coe\n",
      "5\n",
      "Emmylou Harris\n",
      "6\n",
      "Boxcar Willie\n",
      "4\n",
      "Johnny Russell\n",
      "3\n",
      "Jerry Lee Lewis\n",
      "4\n",
      "Backstreet Boys\n",
      "4\n",
      "NSYNC\n",
      "4\n",
      "LFO\n",
      "3\n",
      "O-Town\n",
      "4\n",
      "US5\n",
      "3\n",
      "U.S.\n",
      "5\n",
      "Lou Pearlman\n",
      "4\n",
      "BAFTA Award for Best Film\n",
      "8\n",
      "BAFTA Award for Best Direction\n",
      "8\n",
      "BAFTA Award for Most Promising Newcomer to Leading Film Roles\n",
      "17\n",
      "BAFTA Award for Best Editing\n",
      "8\n",
      "Nichols\n",
      "3\n",
      "Hoffman\n",
      "4\n",
      "Sam O 'Steen\n",
      "6\n",
      "Tropicalismo\n",
      "5\n",
      "Samba\n",
      "3\n",
      "Bossa Nova\n",
      "4\n",
      "MPB\n",
      "3\n",
      "Música popular brasileira\n",
      "9\n",
      "Brazilian Popular Music\n",
      "5\n",
      "Too Fast for Love\n",
      "5\n",
      "Shout at the Devil\n",
      "6\n",
      "Theatre of Pain\n",
      "5\n",
      "the first wave of glam metal\n",
      "7\n",
      "hard rock\n",
      "3\n",
      "heavy metal\n",
      "3\n",
      "Maple Leaf Gardens\n",
      "5\n",
      "Lata Mangeshkar\n",
      "6\n",
      "United Way of Canada\n",
      "5\n",
      "Superunknown\n",
      "3\n",
      "Grammy Award\n",
      "5\n",
      "Soundgarden\n",
      "4\n",
      "Billboard 200\n",
      "4\n",
      "Spoonman\n",
      "4\n",
      "Black Hole Sun\n",
      "4\n",
      "Academy Awards\n",
      "5\n",
      "Academy Award for Best Director\n",
      "8\n",
      "Academy Award for Best Picture\n",
      "8\n",
      "The Godfather Part III\n",
      "6\n",
      "American Idiot\n",
      "4\n",
      "Grammy Award\n",
      "5\n",
      "Grammy Award for Best Rock Album\n",
      "9\n",
      "Grammy Award for Album of the Year\n",
      "10\n",
      "United Kingdom\n",
      "3\n",
      "Official Charts Company\n",
      "5\n",
      "British Phonographic Industry\n",
      "6\n",
      "Recording Industry Association of America\n",
      "7\n",
      "ARIA\n",
      "3\n",
      "panto season\n",
      "4\n",
      "Milton Keynes Theatre\n",
      "5\n",
      "Liverpool Empire Theatre\n",
      "4\n",
      "Captain Hook\n",
      "3\n",
      "The Trilogy\n",
      "3\n",
      "The Maggot\n",
      "4\n",
      "The Bootlicker\n",
      "5\n",
      "The Crybaby\n",
      "4\n",
      "Les Mistigris\n",
      "5\n",
      "Germany\n",
      "2\n",
      "Belgium\n",
      "4\n",
      "France\n",
      "2\n",
      "Turkey\n",
      "2\n",
      "Mistigris\n",
      "4\n",
      "Wales\n",
      "3\n",
      "Gŵyl Gobaith Music Festival\n",
      "9\n",
      "Westenra\n",
      "4\n",
      "Cancer Research UK\n",
      "5\n",
      "Wales Air Ambulance\n",
      "7\n",
      "CLIC Sargent\n",
      "6\n",
      "HeadtoHeart\n",
      "4\n",
      "U.S.\n",
      "5\n",
      "Song Of The Decade\n",
      "6\n",
      "Carey\n",
      "3\n",
      "Billboard\n",
      "3\n",
      "Hero\n",
      "2\n",
      "Without You\n",
      "3\n",
      "All I Want for Christmas Is You\n",
      "8\n",
      "Fantasy\n",
      "3\n",
      "Always Be My Baby\n",
      "5\n",
      "One Sweet Day\n",
      "4\n",
      "Grammy Award s\n",
      "6\n",
      "Brit Awards\n",
      "3\n",
      "American Music Award s\n",
      "5\n",
      "MTV Video Music Award s\n",
      "7\n",
      "Ivor Novello Awards\n",
      "7\n",
      "Michael\n",
      "2\n",
      "Queensrÿche\n",
      "7\n",
      "Fates Warning\n",
      "4\n",
      "Dream Theater\n",
      "3\n",
      "United States\n",
      "3\n",
      "Mirrors\n",
      "3\n",
      "Black Sabbath\n",
      "3\n",
      "Blue Öyster Cult\n",
      "6\n",
      "Cheap Trick\n",
      "4\n",
      "Ted Nugent\n",
      "4\n",
      "Sandy Pearlman\n",
      "5\n",
      "Murray Krugman\n",
      "3\n",
      "Tom Werman\n",
      "4\n",
      "UAAP Season 71\n",
      "5\n",
      "UAAP\n",
      "3\n",
      "Puso\n",
      "4\n",
      "Heart\n",
      "2\n",
      "Straight No Chaser\n",
      "5\n",
      "Pentatonix\n",
      "5\n",
      "The House Jacks\n",
      "5\n",
      "Rockapella\n",
      "4\n",
      "Mosaic\n",
      "4\n",
      "Home Free\n",
      "3\n",
      "M-pact\n",
      "5\n",
      "Grammy Award s\n",
      "6\n",
      "Grammy Lifetime Achievement Award\n",
      "7\n",
      "Grammy Award for Album of the Year Grammy nominations\n",
      "12\n",
      "Simon\n",
      "2\n",
      "You 're the One\n",
      "6\n",
      "Brazil Classics\n",
      "3\n",
      "Samba\n",
      "3\n",
      "Tropicália\n",
      "6\n",
      "Boston Garden\n",
      "3\n",
      "Montreal Forum\n",
      "4\n",
      "Pepsi Forum\n",
      "5\n",
      "Bell Centre\n",
      "3\n",
      "Montreal Canadiens\n",
      "4\n",
      "Bruins\n",
      "4\n",
      "UK\n",
      "2\n",
      "Liverpool\n",
      "2\n",
      "The Cavern Club\n",
      "4\n",
      "London\n",
      "2\n",
      "Mean Fiddler\n",
      "5\n",
      "Glasgow\n",
      "4\n",
      "Barrowland Ballroom\n",
      "6\n",
      "Black Sabbath\n",
      "3\n",
      "Deep Purple\n",
      "3\n",
      "Eagles\n",
      "3\n",
      "Emerson , Lake & Palmer\n",
      "7\n",
      "Rare Earth\n",
      "3\n",
      "Seals and Crofts\n",
      "6\n",
      "Black Oak Arkansas\n",
      "4\n",
      "Earth , Wind & Fire\n",
      "6\n",
      "rock\n",
      "2\n",
      "pop\n",
      "2\n",
      "Tormented\n",
      "3\n",
      "Dysfunction\n",
      "4\n",
      "Break the Cycle\n",
      "4\n",
      "14 Shades of Grey\n",
      "5\n",
      "Chapter V\n",
      "3\n",
      "The Illusion of Progress\n",
      "5\n",
      "Staind\n",
      "4\n",
      "Staind\n",
      "4\n",
      "With the Lights Out\n",
      "5\n",
      "From the Muddy Banks of the Wishkah\n",
      "11\n",
      "Nevermind\n",
      "3\n",
      "Nirvana\n",
      "4\n",
      "Novoselic\n",
      "4\n",
      "Take That\n",
      "3\n",
      "East 17\n",
      "3\n",
      "Gary Barlow\n",
      "4\n",
      "Tony Mortimer\n",
      "4\n",
      "In It for the Money\n",
      "6\n",
      "Supergrass\n",
      "3\n",
      "Life on Other Planets\n",
      "6\n",
      "Road to Rouen\n",
      "5\n",
      "Diamond Hoo Ha\n",
      "4\n",
      "Supergrass Is 10\n",
      "5\n",
      "33rd Academy Awards\n",
      "5\n",
      "Academy Award for Best Picture\n",
      "8\n",
      "Academy Award for Best Director\n",
      "8\n",
      "Academy Award for Best Original Screenplay\n",
      "10\n",
      "The Apartment\n",
      "4\n",
      "Dream On\n",
      "3\n",
      "I Feel Loved\n",
      "5\n",
      "Freelove\n",
      "4\n",
      "Goodnight Lovers\n",
      "5\n",
      "Folk music\n",
      "4\n",
      "funk\n",
      "3\n",
      "Soul music\n",
      "3\n",
      "Hip hop music\n",
      "5\n",
      "Electronic music\n",
      "4\n",
      "alternative rock\n",
      "4\n",
      "Country music\n",
      "3\n",
      "psychedelia\n",
      "4\n",
      "Coldcut\n",
      "3\n",
      "Jon Spencer Blues Explosion\n",
      "5\n",
      "Jon Spencer\n",
      "3\n",
      "Mike Ladd\n",
      "4\n",
      "Everything Is Under Control\n",
      "5\n",
      "Masada Guitars\n",
      "5\n",
      "Masada Recital\n",
      "5\n",
      "Masada Rock\n",
      "4\n",
      "Voices in the Wilderness\n",
      "6\n",
      "The Unknown Masada\n",
      "5\n",
      "Masada\n",
      "3\n",
      "Marc Ribot\n",
      "4\n",
      "Bill Frisell\n",
      "5\n",
      "Tim Sparks\n",
      "3\n",
      "Mark Feldman\n",
      "3\n",
      "Sylvie Courvoisier\n",
      "9\n",
      "Rashanim\n",
      "4\n",
      "AHK-toong BAY-bi Covered\n",
      "12\n",
      "Achtung Baby\n",
      "5\n",
      "Depeche\n",
      "4\n",
      "U2\n",
      "3\n",
      "U2\n",
      "3\n",
      "So Cruel\n",
      "3\n",
      "1973 Summer Universiade\n",
      "6\n",
      "1986 Goodwill Games\n",
      "5\n",
      "2013 World Championships in Athletics\n",
      "6\n",
      "Dookie\n",
      "3\n",
      "Grammy Award\n",
      "5\n",
      "Grammy Award for Best Alternative Music Album\n",
      "10\n",
      "MTV Video Music Award\n",
      "6\n",
      "Video of the Year\n",
      "5\n",
      "New York\n",
      "3\n",
      "Irish-American\n",
      "4\n",
      "Irish\n",
      "2\n",
      "Friendly Sons of St. Patrick\n",
      "8\n",
      "American Irish Historical Society\n",
      "5\n",
      "Benedictines\n",
      "5\n",
      "Cistercians\n",
      "5\n",
      "Trappists\n",
      "4\n",
      "Premonstratensians\n",
      "7\n",
      "military orders\n",
      "3\n",
      "Poland\n",
      "3\n",
      "fall of the communism\n",
      "5\n",
      "rock\n",
      "2\n",
      "Heavy metal music\n",
      "4\n",
      "jazz\n",
      "3\n",
      "Electronic music\n",
      "4\n",
      "New wave music\n",
      "4\n",
      "Blues\n",
      "3\n",
      "country blues\n",
      "3\n",
      "Delta blues\n",
      "3\n",
      "Piedmont blues\n",
      "5\n",
      "urban blues\n",
      "3\n",
      "Chicago blues\n",
      "3\n",
      "West Coast blues\n",
      "4\n",
      "Tony Award\n",
      "3\n",
      "Tony Award for Best Musical\n",
      "6\n",
      "Tony Award for Best Actress in a Musical\n",
      "9\n",
      "Tony Award for Best Featured Actor in a Musical\n",
      "10\n",
      "Lawrence\n",
      "3\n",
      "Brynner\n",
      "4\n",
      "Doe or Die\n",
      "5\n",
      "The Infamous\n",
      "4\n",
      "Only Built 4 Cuban Linx\n",
      "7\n",
      "4,5,6\n",
      "6\n",
      "Mobb Deep\n",
      "4\n",
      "Nas\n",
      "3\n",
      "AZ\n",
      "2\n",
      "Raekwon\n",
      "4\n",
      "Kool G Rap\n",
      "5\n",
      "Ragged Ass Road\n",
      "5\n",
      "Scenery and Fish\n",
      "5\n",
      "I Mother Earth\n",
      "4\n",
      "Tom Cochrane\n",
      "4\n",
      "Like a Girl\n",
      "4\n",
      "Mi Plan\n",
      "3\n",
      "Latin Grammy Award for Latin Grammy Award for Best Female Pop Vocal Album\n",
      "15\n",
      "Spanish\n",
      "2\n",
      "Black Dyke Mills Band\n",
      "6\n",
      "Yorkshire Imperial Band\n",
      "5\n",
      "Yorkshire Copperworks Band\n",
      "6\n",
      "Foden 's\n",
      "6\n",
      "Fairey Band\n",
      "5\n",
      "Leyland Band\n",
      "5\n",
      "ONE Campaign\n",
      "3\n",
      "H2O Africa Foundation\n",
      "6\n",
      "Feeding America\n",
      "4\n",
      "Water.org\n",
      "4\n",
      "Playing to Win\n",
      "4\n",
      "No Reins\n",
      "4\n",
      "Little River Band\n",
      "4\n",
      "Farnham\n",
      "4\n",
      "The Magnificent Moodies\n",
      "6\n",
      "Denny Cordell\n",
      "5\n",
      "Beat music\n",
      "3\n",
      "Rhythm and blues\n",
      "5\n",
      "Decca\n",
      "3\n",
      "Zeppelin I\n",
      "4\n",
      "Led Zeppelin II\n",
      "5\n",
      "Led Zeppelin III\n",
      "5\n",
      "Led Zeppelin IV\n",
      "5\n",
      "Houses of the Holy\n",
      "6\n",
      "Dave Lewis\n",
      "3\n",
      "Carnegie Hall\n",
      "4\n",
      "Big Brothers Big Sisters of America\n",
      "7\n",
      "United Jewish Appeal\n",
      "4\n",
      "Polish Assistance\n",
      "4\n",
      "Musicians Emergency fund\n",
      "5\n",
      "National Association for Mental Health\n",
      "6\n",
      "Legal Defense Fund of the National Advancement of Colored People\n",
      "13\n",
      "Keith Urban\n",
      "3\n",
      "Rod Stewart\n",
      "3\n",
      "Taj Mahal\n",
      "5\n",
      "Joe Satriani\n",
      "5\n",
      "David Hidalgo\n",
      "5\n",
      "Larry Lalonde\n",
      "4\n",
      "Doc Watson\n",
      "3\n",
      "six-string guitar banjo\n",
      "7\n",
      "Anthology 1\n",
      "4\n",
      "Anthology 2\n",
      "4\n",
      "Anthology 3\n",
      "4\n",
      "Rocket Baby Dolls\n",
      "5\n",
      "popular music\n",
      "3\n",
      "Gothic rock\n",
      "5\n",
      "Glam rock\n",
      "4\n",
      "Boonoonoonoos\n",
      "6\n",
      "Ten Thousand Lightyears\n",
      "5\n",
      "Kalimba de Luna - 16 Happy Songs\n",
      "10\n",
      "Eye Dance\n",
      "3\n",
      "Boney M.\n",
      "5\n",
      "United States\n",
      "3\n",
      "Europe\n",
      "2\n",
      "compact disc\n",
      "4\n",
      "bonus tracks\n",
      "4\n",
      "Loretta Lynn\n",
      "5\n",
      "Merle Haggard\n",
      "6\n",
      "Buck Owens\n",
      "4\n",
      "Porter Wagoner\n",
      "6\n",
      "George Jones\n",
      "3\n",
      "Sonny James\n",
      "4\n",
      "the Nashville sound\n",
      "4\n",
      "Andy McCarroll\n",
      "5\n",
      "Moral Support\n",
      "4\n",
      "Undercover\n",
      "3\n",
      "the 77s\n",
      "4\n",
      "Adam Again\n",
      "3\n",
      "Quickflight\n",
      "3\n",
      "Daniel Amos\n",
      "3\n",
      "Youth Choir\n",
      "5\n",
      "the Choir\n",
      "4\n",
      "Lifesavers Underground\n",
      "6\n",
      "the Prayer Chain\n",
      "4\n",
      "Altar Boys\n",
      "4\n",
      "Breakfast with Amy\n",
      "5\n",
      "4-4-1\n",
      "6\n",
      "Steve Scott\n",
      "3\n",
      "Michael Knott\n",
      "4\n",
      "Steve Taylor\n",
      "3\n",
      "David Edwards\n",
      "3\n",
      "Vector\n",
      "2\n",
      "Christian alternative music\n",
      "4\n",
      "Christian punk\n",
      "3\n",
      "new wave\n",
      "3\n",
      "Academy Award for Best Adapted Screenplay\n",
      "11\n",
      "Student Academy Award\n",
      "4\n",
      "BAFTA Award for Best Adapted Screenplay\n",
      "11\n",
      "Emmy Awards\n",
      "4\n",
      "Peabody Award\n",
      "5\n",
      "Cannes Grand Prix\n",
      "6\n",
      "Backstreet Boys\n",
      "4\n",
      "Westlife\n",
      "3\n",
      "Take That\n",
      "3\n",
      "Boyzone\n",
      "3\n",
      "New Kids on the Block\n",
      "6\n",
      "United Kingdom\n",
      "3\n",
      "Europe\n",
      "2\n",
      "max_n_tokens_per_answer 17\n",
      "average_n_tokens_per_answer 4.618827160493828\n"
     ]
    }
   ],
   "source": [
    "n_tokens_for_this_answer = []\n",
    "for sample in dataset_QA_format[\"train\"]:\n",
    "    sample_answers = sample[\"answers\"]\n",
    "    for answer in sample_answers[\"text\"]:\n",
    "        print(answer)\n",
    "        tokenized_examples = tokenizer(\n",
    "            answer,\n",
    "            truncation=\"only_second\",\n",
    "            max_length=MAX_SEQ_LENGTH,\n",
    "            stride=DOC_STRIDE,\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "        input_ids = tokenized_examples['input_ids']\n",
    "        #print(input_ids)\n",
    "        input_ids = np.where(np.array(input_ids) > 1, input_ids, 0)\n",
    "        print(np.count_nonzero(input_ids))\n",
    "        n_tokens_for_this_answer.append(np.count_nonzero(input_ids))\n",
    "\n",
    "max_n_tokens_per_answer = np.max(np.array(n_tokens_for_this_answer))\n",
    "print(\"max_n_tokens_per_answer\", max_n_tokens_per_answer)\n",
    "average_n_tokens_per_answer = np.average(np.array(n_tokens_for_this_answer))\n",
    "print(\"average_n_tokens_per_answer\", average_n_tokens_per_answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict, concatenate_datasets\n",
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# my libraries\n",
    "import data_handler_cross_NER  # to load dataset in BIO format and convert it into QA format for NER\n",
    "\n",
    "\n",
    "def rename_ids(examples):\n",
    "    examples['doc_question_pairID'] = strIDs_to_floatIDs[examples['doc_question_pairID'].split(':')[0]][examples['doc_question_pairID']]\n",
    "    return examples\n",
    "\n",
    "\n",
    "def prepare_features_for_training(examples):\n",
    "    # concatenate the question;document_context and tokenize (adding also RoBERTa special tokens)\n",
    "    # overflows will be automatically treated by using a sliding window approach\n",
    "    # questions are concatenated to the left of the document_context\n",
    "    \"\"\"\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"document_context\"],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=MAX_SEQ_LENGTH,\n",
    "        stride=DOC_STRIDE,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    \"\"\"\n",
    "    # setting padding=longest, padding to the longest sequence in the batch\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"document_context\"],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=MAX_SEQ_LENGTH,\n",
    "        stride=DOC_STRIDE,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=False,  # not padding here\n",
    "    )\n",
    "\n",
    "    # Since one document might produce several passages if it has a long context, we need a map from passages to its corresponding doc-question sample\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # The offset mappings will give us a map from token to character positions in the original context.\n",
    "    # This will help us compute the start_positions and end_positions.\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # in multispan EQA for each sample we may have multiple start_positions & end_positions\n",
    "    # therefore will not be a single int for each sample but a List[int]\n",
    "    # we cannot have variable length Lists when padding, nor we want to impose a maximum number of answers per passage\n",
    "    # we encode spans as multi-1-hot-vectors\n",
    "    tokenized_examples[\"start_positions\"] = [np.zeros(len(offset_mapping[i]), dtype=int) for i in range(len(offset_mapping))]\n",
    "    tokenized_examples[\"end_positions\"] = [np.zeros(len(offset_mapping[i]), dtype=int) for i in range(len(offset_mapping))]\n",
    "\n",
    "    # which are passage tokens and which are question/special tokens\n",
    "    tokenized_examples[\"sequence_ids\"] = [[] for i in range(len(offset_mapping))]\n",
    "\n",
    "    # in passage_id we save the doc_question_pairID that generated it to later collect back passages answers to doc level\n",
    "    tokenized_examples[\"passage_id\"] = []\n",
    "\n",
    "    # new offset_mappings with [-1, -1] if not passage token (added to pad to MAX_SEQ_LENGTH)\n",
    "    tokenized_examples[\"offset_mapping\"] = [[] for i in range(len(offset_mapping))]\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # giving to passageID the ID of the doc-question pair that generated it\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"passage_id\"].append(examples[\"doc_question_pairID\"][sample_index])\n",
    "\n",
    "        # Labeling impossible answers with the index of the CLS token\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)  # i is batch index\n",
    "        # creating mask with 1 marking valid CLS and passage tokens\n",
    "        sequence_ids = np.where(np.array(sequence_ids) == 1, sequence_ids, 0)  # 0 if 0 or None (special tokens and padding tokens to MAX_SEQ_LENGTH)\n",
    "        sequence_ids[0] = 1  # CLS token will be used for not_answerable questions then its token must be treated as passage token\n",
    "        tokenized_examples[\"sequence_ids\"][i] = sequence_ids\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == 1 else (-1, -1))\n",
    "            for k, o in enumerate(offset_mapping[i])\n",
    "        ]\n",
    "\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"answers\"][sample_index]\n",
    "        # If no answers at document level are given, set the cls_index as answer.\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"][i][cls_index] = 1\n",
    "            tokenized_examples[\"end_positions\"][i][cls_index] = 1\n",
    "        else:\n",
    "            atLeastOneAnswer = False\n",
    "            for answer_start_char, answer_text in zip(answers[\"answer_start\"], answers[\"text\"]):\n",
    "                # sequence_ids hides the sequence_ids modified to act as mask for question tokens and passage tokens\n",
    "                # retrieve not modified back\n",
    "                sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "                # Start/end character index of the answer in the text.\n",
    "                start_char = answer_start_char\n",
    "                end_char = start_char + len(answer_text)\n",
    "\n",
    "                # moving start token index to the start of the passage\n",
    "                token_start_index = 0\n",
    "                while sequence_ids[token_start_index] != 1:\n",
    "                    token_start_index += 1\n",
    "\n",
    "                # moving end token index to the end of the passage\n",
    "                token_end_index = len(input_ids) - 1\n",
    "                while sequence_ids[token_end_index] != 1:\n",
    "                    token_end_index -= 1\n",
    "\n",
    "                # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
    "                if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                    tokenized_examples[\"start_positions\"][i][cls_index] = 1\n",
    "                    tokenized_examples[\"end_positions\"][i][cls_index] = 1\n",
    "                else:\n",
    "                    # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
    "                    while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                        token_start_index += 1\n",
    "                    tokenized_examples[\"start_positions\"][i][token_start_index - 1] = 1\n",
    "\n",
    "                    while offsets[token_end_index][1] >= end_char:\n",
    "                        token_end_index -= 1\n",
    "                    tokenized_examples[\"end_positions\"][i][token_end_index + 1] = 1\n",
    "\n",
    "                    atLeastOneAnswer = True  # there is at least one answer in this passage\n",
    "\n",
    "            # it may be that some doc level answer was not in the passage and triggered the CLS position to be 1\n",
    "            # we set it back to 0\n",
    "            if atLeastOneAnswer:\n",
    "                tokenized_examples[\"start_positions\"][i][cls_index] = 0\n",
    "                tokenized_examples[\"end_positions\"][i][cls_index] = 0\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/andrew/.cache/huggingface/hub/models--deepset--roberta-base-squad2/snapshots/e84d19c1ab20d7a5c15407f6954cef5c25d7a261/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"deepset/roberta-base-squad2\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"language\": \"english\",\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"name\": \"Roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at /Users/andrew/.cache/huggingface/hub/models--deepset--roberta-base-squad2/snapshots/e84d19c1ab20d7a5c15407f6954cef5c25d7a261/vocab.json\n",
      "loading file merges.txt from cache at /Users/andrew/.cache/huggingface/hub/models--deepset--roberta-base-squad2/snapshots/e84d19c1ab20d7a5c15407f6954cef5c25d7a261/merges.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /Users/andrew/.cache/huggingface/hub/models--deepset--roberta-base-squad2/snapshots/e84d19c1ab20d7a5c15407f6954cef5c25d7a261/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /Users/andrew/.cache/huggingface/hub/models--deepset--roberta-base-squad2/snapshots/e84d19c1ab20d7a5c15407f6954cef5c25d7a261/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/andrew/.cache/huggingface/hub/models--deepset--roberta-base-squad2/snapshots/e84d19c1ab20d7a5c15407f6954cef5c25d7a261/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"deepset/roberta-base-squad2\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"language\": \"english\",\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"name\": \"Roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/andrew/.cache/huggingface/hub/models--deepset--roberta-base-squad2/snapshots/e84d19c1ab20d7a5c15407f6954cef5c25d7a261/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"deepset/roberta-base-squad2\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"language\": \"english\",\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"name\": \"Roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: deepset/roberta-base-squad2 has context window size of 512\n",
      "{'album': 'A music album is a collection of audio recordings, typically songs, that are released together as a single package. Which are albums in the document ?', 'award': 'A music award is like a prize given to musicians or groups to acknowledge their achievements in areas like singing, writing music, and producing. Which are awards in the document ?', 'band': 'A music band is a group of musicians who play instruments and/or sing together. Which are bands in the document ?', 'country': 'A country is a distinct geographical area with its own government, borders, and population. Which are countries in the document ?', 'event': 'An event is a planned and organized occasion or happening, often with a specific purpose or goal, where people gather to participate or observe. Which are events in the document ?', 'location': 'A location is a specific place or position, usually defined by its geographical coordinates, where something exists or events occur. Which are locations in the document ?', 'misc': 'Apart from albums, awards, bands, countries, events, locations, musical artists, musical instruments, music genres, organisations, people and songs, which are other relevant information in the document ?', 'musicalartist': 'A musical artist is an individual involved in creating, performing, and often composing music. Which are musical artists in the document ?', 'musicalinstrument': 'A musical instrument is a tool or device to make music. Which are musical instruments in the document ?', 'musicgenre': 'A music genre is a category that classifies music based on shared characteristics, such as musical style, cultural influences, and thematic elements. Which are genres in the document ?', 'organisation': 'An organization is a structured group of people with a common goal, purpose, or function, often working together to achieve specific objectives. Which are organisations in the document ?', 'person': 'A person is an individual human being. Which are person but not musical artists in the document ?', 'song': 'A song is a musical composition typically consisting of lyrics and melody, often intended for singing or performance. Which are songs in the document ?'}\n",
      "Dataset converted to QA format: \n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['doc_question_pairID', 'document_context', 'tagName', 'question', 'answers'],\n",
      "        num_rows: 1300\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['doc_question_pairID', 'document_context', 'tagName', 'question', 'answers'],\n",
      "        num_rows: 4940\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['doc_question_pairID', 'document_context', 'tagName', 'question', 'answers'],\n",
      "        num_rows: 6045\n",
      "    })\n",
      "    dataset_name: music\n",
      "})\n",
      "some samples:\n",
      "{'doc_question_pairID': 'train:0:0', 'document_context': 'In 2003 , the Stade de France was the primary site of the 2003 World Championships in Athletics .', 'tagName': 'album', 'question': 'A music album is a collection of audio recordings, typically songs, that are released together as a single package. Which are albums in the document ?', 'answers': {'answer_start': [], 'text': []}}\n",
      "{'doc_question_pairID': 'train:0:1', 'document_context': 'In 2003 , the Stade de France was the primary site of the 2003 World Championships in Athletics .', 'tagName': 'award', 'question': 'A music award is like a prize given to musicians or groups to acknowledge their achievements in areas like singing, writing music, and producing. Which are awards in the document ?', 'answers': {'answer_start': [], 'text': []}}\n",
      "{'doc_question_pairID': 'train:1:10', 'document_context': 'In addition to relentless touring in the U.S. and Canada , PUSA made multiple tours of Europe , Australia , New Zealand and Japan .', 'tagName': 'organisation', 'question': 'An organization is a structured group of people with a common goal, purpose, or function, often working together to achieve specific objectives. Which are organisations in the document ?', 'answers': {'answer_start': [], 'text': []}}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f5cae5017b4dbaa4d156daaaa45b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1300 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c581fb874a9b46b194ef36316b85e4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4940 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3f1376c6464f8588faf083f1fd1ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6045 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a168316db834463fa1aa2ccdbc693667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yx/13w51czj41z7f6qw20hl5bsm0000gn/T/ipykernel_17530/3593170379.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# building tokenized datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mtokenized_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_QA_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare_features_for_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_QA_format\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_datasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    774\u001b[0m             \u001b[0mcache_file_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         return DatasetDict(\n\u001b[0;32m--> 776\u001b[0;31m             {\n\u001b[0m\u001b[1;32m    777\u001b[0m                 k: dataset.map(\n\u001b[1;32m    778\u001b[0m                     \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    775\u001b[0m         return DatasetDict(\n\u001b[1;32m    776\u001b[0m             {\n\u001b[0;32m--> 777\u001b[0;31m                 k: dataset.map(\n\u001b[0m\u001b[1;32m    778\u001b[0m                     \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m                     \u001b[0mwith_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2572\u001b[0;31m             return self._map_single(\n\u001b[0m\u001b[1;32m   2573\u001b[0m                 \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2574\u001b[0m                 \u001b[0mwith_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         }\n\u001b[1;32m    550\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   2966\u001b[0m                         )  # Something simpler?\n\u001b[1;32m   2967\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2968\u001b[0;31m                             batch = apply_function_on_filtered_inputs(\n\u001b[0m\u001b[1;32m   2969\u001b[0m                                 \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2970\u001b[0m                                 \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[0;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   2850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m                 \u001b[0madditional_args\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2852\u001b[0;31m             \u001b[0mprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2853\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mupdate_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m                 \u001b[0;31m# Check if the function returns updated examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(item, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2530\u001b[0m                 )\n\u001b[1;32m   2531\u001b[0m                 \u001b[0;31m# Use the LazyDict internally, while mapping the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2532\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecorated_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2533\u001b[0m                 \u001b[0;31m# Return a standard dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyDict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/yx/13w51czj41z7f6qw20hl5bsm0000gn/T/ipykernel_17530/2385653480.py\u001b[0m in \u001b[0;36mprepare_features_for_training\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0msample_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0manswers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;31m# If no answers at document level are given, set the cls_index as answer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answer_start\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/yx/13w51czj41z7f6qw20hl5bsm0000gn/T/ipykernel_17530/2385653480.py\u001b[0m in \u001b[0;36mprepare_features_for_training\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0msample_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0manswers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;31m# If no answers at document level are given, set the cls_index as answer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answer_start\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   1974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads_suspended_single_notification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_thread_suspended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m                 \u001b[0mkeep_suspended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m         \u001b[0mframes_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py\u001b[0m in \u001b[0;36m_do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_internal_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_async_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_current_thread_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "pretrained_model_relying_on = 'deepset/roberta-base-squad2'\n",
    "\n",
    "# loading tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_relying_on)\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)\n",
    "\n",
    "MODEL_CONTEXT_WINDOW = tokenizer.model_max_length\n",
    "print(\"Model: {} has context window size of {}\".format(pretrained_model_relying_on, MODEL_CONTEXT_WINDOW))\n",
    "\n",
    "MAX_SEQ_LENGTH = 256  # question + context + special # 128 for conll2003, 256 for others\n",
    "assert MAX_SEQ_LENGTH <= MODEL_CONTEXT_WINDOW, (\"MAX SEQ LENGTH must be smallerEqual than model context window\")\n",
    "MAX_QUERY_LENGTH = 48\n",
    "DOC_STRIDE = 64  # overlap between 2 consecutive passages from same document, 32 for conll2003\n",
    "assert DOC_STRIDE < (MAX_SEQ_LENGTH - MAX_QUERY_LENGTH), (\"DOC_STRIDE must be smaller, otherwise parts of the doc will be skipped\")\n",
    "\n",
    "# name of the dataset to convert to QA and tokenize\n",
    "path_to_cross_NER_datasets = \"../../datasets/CrossNER/ner_data\"\n",
    "#path_to_cross_NER_datasets = \"./datasets/CrossNER/ner_data\"\n",
    "dataset_name = \"music\"\n",
    "\n",
    "# loading dataset in BIO format\n",
    "dataset_BIO_format = data_handler_cross_NER.build_dataset_from_txt(os.path.join(path_to_cross_NER_datasets, dataset_name))\n",
    "\n",
    "# converting to QA for NER format (building document;question;gold_answers dataset)\n",
    "#path_to_questions = os.path.join(\"./cross_ner_questions_simpler/\", dataset_name + \".txt\")\n",
    "path_to_questions = os.path.join(\"./cross_ner_questions/\", dataset_name + \".txt\")\n",
    "dataset_QA_format = data_handler_cross_NER.build_dataset_QA_format(dataset_BIO_format, path_to_questions)\n",
    "\n",
    "print(\"Dataset converted to QA format: \")\n",
    "print(dataset_QA_format)\n",
    "\n",
    "print(\"some samples:\")\n",
    "print(dataset_QA_format[\"train\"][0])\n",
    "print(dataset_QA_format[\"train\"][1])\n",
    "print(dataset_QA_format[\"train\"][23])\n",
    "\n",
    "dataset_name = dataset_QA_format.pop(\"dataset_name\")\n",
    "\n",
    "# Shuffling question-document samples to not have all questions for a document grouped\n",
    "dataset_QA_format = dataset_QA_format.shuffle()\n",
    "\n",
    "# dict for str <--> float ID renaming\n",
    "strIDs_to_floatIDs = {splitName: {} for splitName in dataset_QA_format.keys()}\n",
    "i = 0.5\n",
    "for splitName in dataset_QA_format.keys():\n",
    "    for sample in dataset_QA_format[splitName]:\n",
    "        strIDs_to_floatIDs[splitName][sample['doc_question_pairID']] = i\n",
    "        i += 1\n",
    "# inverting dict\n",
    "floatIDs_to_strIDs = {splitName: {} for splitName in strIDs_to_floatIDs.keys()}\n",
    "for splitName in strIDs_to_floatIDs.keys():\n",
    "    floatIDs_to_strIDs[splitName] = {v: k for k, v in strIDs_to_floatIDs[splitName].items()}\n",
    "\n",
    "# RENAMING str IDs to Float IDs\n",
    "dataset_QA_format[\"train\"] = dataset_QA_format[\"train\"].map(rename_ids, batched=False)\n",
    "dataset_QA_format[\"validation\"] = dataset_QA_format[\"validation\"].map(rename_ids, batched=False)\n",
    "dataset_QA_format[\"test\"] = dataset_QA_format[\"test\"].map(rename_ids, batched=False)\n",
    "\n",
    "# saving dataset_doc_quest_ans\n",
    "# dirToSaveTo = \"../../datasets/CrossNER_QA_format_simpler\"\n",
    "dirToSaveTo = \"./datasets/CrossNER_QA_format\"\n",
    "os.makedirs(os.path.join(dirToSaveTo, dataset_name))\n",
    "with open(os.path.join(dirToSaveTo, dataset_name, 'dataset_doc_quest_ans.pickle'), 'wb') as handle:\n",
    "    pickle.dump(dataset_QA_format, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# building tokenized datasets\n",
    "tokenized_datasets = dataset_QA_format.map(prepare_features_for_training, batched=True, remove_columns=dataset_QA_format[\"train\"].column_names)\n",
    "print(tokenized_datasets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
